\documentclass{statsoc}
\usepackage[a4paper]{geometry}   % otherwise statsoc class doesn't compile to A4 correctly
%\usepackage{setspace}
%\doublespacing

\usepackage[hidelinks]{hyperref} % auto detect ref type
\usepackage{natbib}
%\setcitestyle{rss}

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{caption}
\usepackage{textcomp}    % for Hawaii characters
\usepackage{url}

% new commands
\newcommand{\wt}[1]{\widetilde{#1}}
\newcommand{\ol}[1]{\overline{#1}}
\newcommand{\wh}[1]{\widehat{#1}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\T}{\intercal}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\bS}{\mathbf{S}}
\newcommand{\bQ}{\mathbf{Q}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bm}{\boldsymbol}  % bold maths symbols
\newcommand{\tl}{\tilde{\lambda}}   % thinned little lambda
\newcommand{\tL}{\tilde{\Lambda}}  % thinned big lambda

% RJC 09/08/2019 Added shortcuts for Hawaiian words
\newcommand{\akepa}{\textquotesingle\={a}kepa}  % adds Hawaiian diacritical marks
\newcommand{\Akepa}{\textquotesingle\={A}kepa}  % adds Hawaiian diacritical marks
\newcommand{\hawaii}{Hawai\textquotesingle i}   % adds Hawaiian diacritical marks
\DeclareMathOperator*{\argmax}{arg\,max}  % * means _ puts thing beneath operator

\title[One-stage point transect distance sampling using iterated INLA]{One-stage point transect distance sampling using iterated integrated nested Laplace approximations}

\author[Andrew E. Seaton {\it et al.}]{Andrew E. Seaton}
\address{School of Biodiversity, One Health and Veterinary Medicine, 
	University of Glasgow, 
	Glasgow,
	UK}
\email{andrew.seaton.2@glasgow.ac.uk}

\author{Janine B. Illian}
\address{School of Mathematics and Statistics, University of Glasgow, Glasgow, UK}

\author{Finn Lindgren}
\address{School of Mathematics, University of Edinburgh, Edinburgh, UK}

\author{Richard J. Camp}
\address{U. S. Geological Survey, Pacific Island Ecosystems Research Center, P.O. Box 44, \hawaii{} National Park, HI 96718, U.S.A.}

% seems like this document class uses short author from the last author
% macro in the preamble?  
\author[Andrew E. Seaton \textit{et al.}]{Steve J. Kendall}
\address{U. S. Fish and Wildlife, Big Island National Wildlife Refuge Complex, 60 Nowelo St., Suite 100, Hilo, HI  96720, U.S.A.}

\begin{document}

\begin{abstract}
Distance sampling methods aim to estimate the size and spatial distribution of populations of wild animals.  In traditional analyses, spatial modelling is conducted in a second modelling stage, conditional on estimates of the detectability of animals. Here we present a one-stage analysis that simultaneously estimates the detectability and spatial distribution of an endangered tropical bird population.  We take a point process perspective, modelling animal locations as a thinned log-Gaussian Cox process.

Since the thinning process is non-linear, we cannot use standard methods for inference. To address this we use a novel approximate Bayesian inference approach based on an iterative scheme of model fits using integrated nested Laplace approximations (INLA).  This approach is general, flexible and applicable to a wide variety of non-linear model specifications. To illustrate the value of the one-stage approach we hypothesise potential model outputs that are relevant for conservation science.  Since model outputs are based on samples from the joint posterior, they naturally account for the uncertainty in the detection process, a key advantage of the one-stage model. 

\end{abstract}

\keywords{Distance sampling, Estimating abundance, Integrated nested Laplace approximation, Point processes, Spatial statistics, Species distribution modelling}

\section{Introduction}

The estimation of the size and spatial distribution of wild populations of animals is a critical objective within ecology and conservation \citep{schwarz_estimating_1999}. Here we present an analysis of wildlife survey data collected on a critically endangered Hawaiian forest bird that aims to meet this objective.  The \hawaii{} \akepa{} (hereafter \akepa{}; \textit{Loxops coccineus}; nomenclature according to \citealp{usfws_akepa_1970}) is an endemic species whose population declined dramatically during the 20th century  \citep{usfws_revised_2006, judge_akepa_2018}.  The remaining population is the focus of sustained conservation efforts and monitoring is required to inform decision-makers about changes in the overall abundance and spatial distribution.  This information is critical when decisions about conservation strategies are made.  However, estimating the abundance and spatial distribution of wild populations of animals presents many statistical challenges.

First, as in many ecological surveys, it is impossible to undertake a full census (i.e. the complete enumeration of all individuals within a defined study region).  The existing population numbers in the thousands and lives in dense tropical forest where logistical and ecological challenges mean a census is not feasible.  For this reason, a monitoring survey must sub-sample appropriately in space and time.  For the \akepa{} this takes the form of the \hawaii Forest Bird Survey (HFBS) \citep{scott_HFBS_1986}, which is a large-scale, quantitative survey of Hawaiian forest birds.  Annual surveys of the \akepa{} study-region consist of a number of point transects located along randomly located line transects.

Second, even at surveyed locations, the detectability of animals is unknown.  The \akepa{} survey estimates detectability using a point transect distance sampling approach \citep{buckland_distance_2015} where, for each observation, the distance to the observer is recorded.  The probability of detecting a bird is modelled using a parametric detection function that decays with increasing distance.  The detection function parameters are estimated from the observed distances by assuming the true density is uniform with respect to distance and attributing deviations from uniformity to imperfect detectability. The combination of spatio-temporal subsampling and unknown detectability means statistical methods to analyse distance sampling data must model a complex observation process alongside the spatial distribution of animals.  

Third, a key aim of the analysis is to predict animal density at unsurveyed locations.  If animal density is modelled using spatial covariates then the covariate effects estimated in the surveyed region can be extrapolated to unsurveyed location.  However, in many ecological contexts there can be good reason to believe there are drivers of the spatial distribution for which we have no explanatory covariates available or for which, in principle, no covariate could be constructed (e.g. the `sociality' of the species).  For the \akepa{} data, one example of an unexplained driver of the spatial distribution is a north-south gradient for which no straightforward explanatory cause has been found \citep{camp_dsm_2020}.  From a statistical perspective, this heterogeneity that cannot be explained by available covariates suggests the inclusion of spatially structured random effects in the model.  Such effects require a careful consideration of the model structure and inference methods to ensure that model fitting remains computationally feasible.

Lastly, the above challenges mean the resulting statistical model is necessarily complex. It is therefore challenging to communicate the results of the analysis to non-statistically trained audiences.  The \akepa{} data are collected with the clear objective of monitoring the population and informing conservation management decisions.  These decisions will be taken by stakeholders with a range of statistical expertise.  This final step of communicating results should therefore be considered with as much care as the rest of the analysis.  This requires the input of statisticians to ensure uncertainty is appropriately captured and communicated in the key outputs of the analysis upon which decisions will be based.  In particular, in the context of species distribution modelling, we note the challenge of communicating uncertainty in maps of predicted animal density.

We present an analysis that addresses these statistical challenges by using the following approaches:

\begin{enumerate}[(a)]
	\item A spatial point process perspective on point transect distance sampling and representing the detection model as a thinning of a point processes.
	\item A one-stage approximate Bayesian approach to inference based on repeated model fits using integrated nested Laplace approximations (INLA) \citep{rue_approximate_2009}.  This allows for the simultaneous estimation of the spatial distribution and detectability of animals.
	\item A computationally efficient Gaussian Markov random field (GMRF) spatially structured random effect specified through a stochastic partial differential equation (SPDE) approach \citep{lindgren_explicit_2011} to account for unobserved drivers of the spatial distribution.
	\item A discussion on model evaluation and communication of results that takes advantage of the one-stage approach by sampling from the joint posterior of all model parameters. We advocate for excursions methods \citep{bolin_excursion_2015} as a way to handle uncertainty in spatial predictions of density.  
\end{enumerate}

We demonstrate several novel contributions to the problem of species distribution modelling under unknown detectability.  This is, to the best of our knowledge, the first analysis of point transect distance sampling data using a point process perspective.  This requires a modified intensity function that accounts for incomplete location information for animal sightings.  This is also the first application of a novel approximate Bayesian inference method to estimate the detection function jointly with the spatial model.  This inference method is readily generalisable to other applications beyond distance sampling models.  As such, this analysis will be of interest to the broad applied statistics community in general, as well as those specifically interested in modelling species distributions.

The rest of the paper proceeds as follows:  Section \ref{sec-study-design} describes the \akepa{} study region and survey design; Section \ref{sec-ds-pp} reviews current approaches to distance sampling and presents the point process perspective; Sections \ref{sec-iinla} and \ref{sec-gmrf} describe the iterated INLA fitting procedure and the GMRF random effect; and Sections \ref{sec-results} presents results of the analysis and discusses model evaluation and effective communication of uncertainty.


\section{Study design}
\label{sec-study-design}

The \hawaii{} \akepa{} is an internationally and federally endangered Hawaiian honeycreeper (\citealp{usfws_akepa_1970, birdlife_akepa_2016}) that is endemic to \hawaii{} Island, USA.  Large-scale, quantitative surveys of Hawaiian forest birds and their habitat commenced in the mid-1970s through the HFBS \citep{scott_HFBS_1986}. Information from the HFBS is used to update the International Union for Conservation of Nature redlist \citep{iucn_redlist_2022}, where the \akepa{} is currently listed as endangered. HFBS data is also used to establish preserves that coincide with native bird hotspots, including Hakalau Forest National Wildlife Refuge on \hawaii{} Island (hereafter Hakalau).  Hakalau is the first wildlife refuge established in \hawaii{} with the primary purpose to protect and manage native forests for the conservation of threatened and endangered bird and plant species. Due to its broad-scale coverage and robust design, the HFBS has become an invaluable dataset used to determine changes in bird species distributions, population sizes and trends in density patterns over time.

During the 20th century, the \akepa{} population declined dramatically due to habitat modification \citep{scott_HFBS_1986, pratt_avifaunal_1994},  mosquito-transmitted avian diseases \citep{pratt_avifaunal_1994, atkinson_wildlife_1995}, introduced predators \citep{lepson_akepa_1997}, and food resources competitors \citep{lepson_akepa_1997}. \Akepa{} has a global abundance of approximately 16,200 (95\%CI 10,000\textendash25,200) birds that is now restricted to five spatially distinct populations \citep{judge_akepa_2018}. Hakalau supports the largest remaining distinct \akepa{} population which, in 2012, was estimated at more than 11,000 birds \citep{camp_statespace_2016}. Maintaining and expanding the \akepa{} population at Hakalau is a primary conservation concern. Unbiased and precise abundance estimates are therefore required by land and resource managers for the purposes of evaluating management actions and developing future management plans.

\subsection{Study area and survey design}

Hakalau was established in 1985 to conserve 15,390 ha of montane forest habitat for native forest birds and rainforest plants. Annual forest bird surveys were initiated in 1987 to determine the population status and track trends in abundance. Survey points were established along 14 line transects following a systematic, random design with point transects located approximately 150m apart on line transects located either 500m or 1,000m apart. We limit our study area to the open-forest and closed-forest strata of Hakalau (\autoref{fig:2002studyareapointspt}), an extension of the area considered in \cite{camp_population_2010, camp_statespace_2016}, who omitted the closed-forest stratum because it was not sampled in the early years of the surveys.  For our analysis, we use data from a later year in which the closed-forest stratum was sampled and so we are able to include it.  The open-forest stratum was previously heavily grazed, and, since the removal of cattle in 1988, regeneration has proceeded naturally \citep{maxfield_hakalau_1998}. The closed-forest stratum was historically least modified by grazing and is relatively intact forest habitat.  The northern boundary of the study area follows the refuge boundary while to the east it is bounded by a fence line (Fig. \ref{fig:2002studyareapointspt}). The southern boundary is the same as that in \cite{camp_population_2010}, chosen to exclude unsurveyed regions to the south of Hakalau but does not represent a physical boundary. To the west of the study area is pasture that is dominated by grass and is unsuitable habitat for \akepa{} and the boundary here marks the edge of the forest.

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.5]{figures/study_area_design.png}
	\caption{Study area showing the 2002 survey points (black dots) in Hakalau Forest National Wildlife Refuge, \hawaii{} Island.  Eastings and Northings are in kilometres.}
	\label{fig:2002studyareapointspt}
\end{figure}

The survey follows a point-transect distance sampling design, recording the horizontal distances from observers to detected birds. Surveys commenced at dawn and continued until 11:00 or halted when weather conditions exceeded prescribed conditions that hindered detecting birds (light rain, and wind and gust strength greater than Beaufort scale 3). During 8-minute counts, trained observers recorded the species, distance to the nearest metre and detection type for each bird detected, along with the sampling conditions cloud cover, rain, wind strength, gust strength, and time of day each point was surveyed.  \cite{camp_population_2010,camp_statespace_2016} provide a detailed description of Hakalau, the study area and the bird surveys.

The survey data used in this analysis is available for download \citep{camp_datarelease_2002} and the full time series data was analysed in a spatio-temporal context in \citep{camp_dsm_2020}.  For the purposes of our analysis we select a single survey year from the \akepa{} time series (2002) that contains a broad sampling of the study area with sufficient numbers of detections to estimate detectability. In 2002, there were a total of 289 point transects sampled within the 4,603 ha study area of Hakalau (Fig. \ref{fig:2002studyareapointspt}).  A total of 276 \akepa{} were detected on 121 point transects. The number of detections within each point transect ranged from zero to six. We selected data from a single year to demonstrate our approach in a simplified setting that does not require a temporal model component.  The choice of year is somewhat arbitrary and the model has also been tested analysing data from other years with similar results to those presented here.  However, our approach is readily extendible to a multi-year analysis, similar to that in \cite{camp_dsm_2020}, which we discuss in more detail in Section \ref{sec-discussion}.

\vfill

\section{Distance sampling as a thinned point process}
\label{sec-ds-pp}

\subsection{Overview of distance sampling methods}

Distance sampling methods aim to estimate abundance by using a spatially explicit sampling design and a parametric detection function to estimate the detectability of animals as a function of distance from transect or observer \citep{buckland_distance_2015}.  Standard distance sampling approaches use a hybrid of design- and model-based inference to estimate population size.  The probability of detection is modelled using a parametric equation and, given estimates of detectability, a randomized sampling design allows for the construction of Horvitz-Thompson-like estimators of animal density \citep{ buckland_advanced_2004, horvitz_generalization_1952}.  Under this approach, animal density is uniform within each strata of the survey.  

More recently, interest has focused on fully model-based approaches that model a spatially varying animal density and allow for the use of non-random survey designs.  These methods allow animal density to be associated with spatially-indexed covariates and non-parametric random effects.  Therefore, animal density can, in principle, be estimated or predicted for any subregion within the study area \citep{buckland_model-based_2016, miller_spatial_2013, johnson_model-based_2010}.  As such, varying density estimates are not restricted by the stratification design required for Horvitz-Thompson-like estimators.  This additional flexibility to make predictions for smaller, user-specified geographic units, and extrapolate relationships to unsurveyed regions has made model-based distance sampling a common approach in the literature \citep{garciabaron_modelling_2019, herr_aerial_2019, breen_new_2017, williams_chilean_2011, stokes_monitoring_2010, williams_modeling_2006}.

Model-based distance sampling has most commonly been implemented in a two-stage modelling framework.  In the first stage, detectability is estimated using the frequency of observed distances to fit the detection function.  In the second stage, detectability estimates from the first stage are used as an offset in a generalized additive model framework.  Detections are are binned into counts within user-defined sampling units (usually point transects or segments of line transects) and an appropriate response distribution is chosen to model these counts.  The \texttt{dsm} package \citep{miller_spatial_2013}, for example, provides tools to do this using the \texttt{R} package \texttt{mgcv} \citep{wood_gam_2017} to implement the spatial count model.   Due to the often sparse nature of wildlife survey data, this may require consideration of over- or under-dispersion and zero-inflated distributions and the negative-binomial or Tweedie distributions are common choices.  This two-stage approach has come under the name \textit{density surface models} and \cite{miller_spatial_2013} provide a review.

A key concern with the two-stage approach is the propagation of uncertainty from the detection model to the spatial model.  Early attempts to address this focused on bootstrapping \citep{hedley_spatial_2004, lahiri_resampling_2003} but more recent work has pointed to potential difficulties with the bootstrapping approach, noting the difficulty of choosing the resampling units when combining spatially structured random effects and spatial bootstraps \citep{bravington_VariancePropagationDensity_2021, williams_chilean_2011}. Instead, \cite{bravington_VariancePropagationDensity_2021} propose avoiding bootstrapping by propagating error based on a second-order Taylor approximation of the detection function at the first-stage maximum-likelihood estimate.

Concerns about uncertainty propagation can be avoided by using one-stage modelling approaches.  A popular one-stage maximum-likelihood method, introduced by \cite{royle_ModelingAbundanceEffects_2004} and implemented in the \texttt{R} package \texttt{unmarked} \citep{fiske_UnmarkedPackageFitting_2011}, is based on reformulating the model as a multinomial likelihood.  This depends on choosing discrete distance classes and binning the data into counts defined on discrete spatial units.  Given these discrete units, the likelihood can be written in a multinomial form and, by marginalising out site specific abundance, a Poisson likelihood that can be optimised to achieve one-stage inference.  This approach rests heavily on the discretisation of both the distance data and the spatial location data.  Below we present a point process perspective that does not require this discretisation step in either the distance or spatial location data.  The \texttt{unmarked} package also does not implement spatially structured random effects, something that we use here and is also popular in the two-stage approach implemented using \texttt{mgcv}.  

Bayesian one-stage approaches have tended to use Markov chain Monte Carlo (MCMC) methods for inference along with data augmentation to model unobserved individuals or groups \citep{schmidt_using_2012}.  \citet{oedekoven_bayesian_2014} present a one-stage model that avoids data augmentation by specifying a combined likelihood of the detection and spatially-explicit count models and incorporated model uncertainty using reversible jump MCMC.

The only Bayesian one-stage analysis that does not use MCMC is, to the best of our knowledge, \citet{yuan_point_2017}, who use INLA \citep{rue_approximate_2009} and present an application on line transect distance sampling data.  \citet{yuan_point_2017} take a point process perspective and formulate the detection model as a thinning of a point pattern.  Key to their approach is formulating the detection model as the solution to an SPDE.  An approximate solution the SPDE is constructed using a B-spline basis and finite element methods which results in a sparse prior precision matrix for the detection model parameters which can be incorporated into the model in INLA.  

A major downside to this approach is that the solutions to the detection model SPDE are not necessarily monotonically decreasing, usually a key feature of detection functions.  The authors' suggestion to reject any non-monotonically decreasing functions when sampling from the posterior is potentially computationally wasteful. Representing the observation model as an SPDE also differs substantially from standard distance sampling models that use a parametric model for the detection function.  Furthermore, parametric forms of detection functions are readily extendible by including covariates and random effects to explain variation in detectability.  It is not clear how to do this using the SPDE implementation in INLA.  These differences with traditional distance sampling methods have perhaps lead to low uptake amongst practitioners of this approach, despite the computational advantages of INLA and the benefits of a one-stage modelling process.  

Here we present an approach that is related to \citet{yuan_point_2017} but with some key differences. We also fit the model using INLA and take advantage of the benefits the increased computational efficiency compared to MCMC.  However, we avoid the issues with the SPDE detection model, instead allowing the user to specify a parametric family of detection functions, such as the half-normal detection function, as will be more familiar to users of classical distance sampling methods. However, this parametric form results in components of the additive predictor that are non-linear in their parameters, making model fitting infeasible in the \texttt{R-INLA} implementation of INLA \citep{rue_approximate_2009}.  We address this by using a method of iterated model fits based on a first-order Taylor expansion of the non-linear model components and implemented in the \texttt{inlabru} package \citep{bachl_inlabru_2019}.

We fit the model to point transect \akepa{} data, which differ from line transect methods in that there is a need to account for the increasing area surveyed as distance increases from the transect.  Our analysis is, to the best of our knowledge, the first analysis of point transect distance sampling data formulated as a thinned point process.  However, the point process framework is not new and has been applied numerous times in analyses of line transect data \citep{buckland_model-based_2016, niemi_bayesian_2010, johnson_model-based_2010, waagepetersen_likelihood-based_2006, hedley_spatial_2004,  hogmander_random_1991, stoyan_remark_1982}.

\subsection{Model specification}

This section describes the statistical model for the spatial pattern of observed animal locations. We assume the location of animals are a point pattern that follows a log-Gaussian Cox process with intensity process $\lambda$, i.e.  the intensity at location $\bs$ is a random variable denoted $\lambda(\bs)$.  The log-Gaussian Cox process is a flexible model that can include spatial covariates to model the mean intensity as well a mean-zero spatially structured random effect to account for unexplained heterogeneity not captured by the covariates \citep{moller_log_1998}.  To account for the imperfect detection of points we specify a thinning probability function $g(\bs) = \mathbb{P}(\text{a point at $\bs$ is detected } |\text{ a point is at $\bs$})$. A key property of the log-Gaussian Cox process is that the point pattern of \textit{detected} points itself follows a log-Gaussian Cox process with intensity process $\tl(\bs) := \lambda(\bs)g(\bs)$.  Using a log link $\log g(\bs)$ is therefore included in the model as an additive component to the model for $\log \lambda(\bs)$.  

Distance sampling models specify the thinning function $g(\bs)$ as a function that decays with increasing distance.  The type of distance measured depends on the type of survey.  For line transects the perpendicular distance to the transect line is used whereas for point transects it is the horizontal distance to the observer.  For the remainder of the paper we assume a point transect survey design and hence horizontal distance to an observer located at the centre of each point transect.  

The thinning probability function is specified as a parametric family of functions. For example, if $r(\bs)$ denotes the distance of a point at $\bs$ from an observer, the half-normal thinning probability function is $g(\bs | \sigma) = \exp(-r(\bs)^2 / 2\sigma^2)$, where $\sigma^2 > 0$ is a variance parameter to be estimated.  Other types of detection function, such as hazard-rate, negative exponential, can also be used. Their parameters themselves can be modelled using appropriate link functions to incorporate covariates that may affect detectability.  In addition to these parametric forms, additional adjustments have been proposed to increase the flexibility of such models by including trigonometric series expansions \citep{buckland_distance_2015}.  

In this analysis we assume a half-normal detection function with no covariates on detection parameters to demonstrate the approach in a simplified setting.  The detection function parameters can only be estimated if an assumption is made about $\lambda(\bs)$ otherwise $g(\bs)$ and the intensity are confounded.  The standard assumption in distance sampling is that the intensity is constant with respect to changes in $r(\bs)$. The usual approach for two stage models is to assume $\lambda(\bs)$ is constant within each spatial unit, however we are able to relax this assumption slightly to allow $\lambda(\bs)$ to be a linear function within each transect.  Given such an assumption, any observed deviations from uniformity can be attributed to detectability and not to variation in the intensity.

A point transect distance sampling survey consists of a set of $K$ point transects.   We denote $k$th subset of space covered by the $k$th point transect as $\Omega_k \subset \mathbb{R}^2$ and the total surveyed region is $\Omega = \cup_{k=1}^K \Omega_k$.  For simplicity, we assume that all point transects are non-overlapping disks with equal radius $W$, as is the case in the HFBS survey.  It would be straightforward to relax this assumption.  The probability of observing a point at location $\bs \in \Omega_k$ given it is at $\bs \in \Omega_k$ we denote $g_k(\bs)$.  The probability of observing a point outside the surveyed region is zero.
Since the point transects are non-overlapping, each location $\bs \in \Omega$ is unambiguously associated with a single thinning probability function $g_k$.  For example, letting $\bs_k$ denote the centre of transect $\Omega_k$, the half-normal thinning probability function for points in $\Omega_k$ is $g_k(\bs) = \exp(-\lVert \bs - \bs_k \rVert_2^2 / 2\sigma^2)$.  The assumption of non-overlapping survey regions could be relaxed by including extra information such as the time of each observation.  The thinning probability function for any $\bs \in \Omega$ is then given by $g(\bs) = g_{k(\bs)}(\bs)$ where $k(\bs)$ is an indexing function such that $k(\bs) = k$ for $\bs \in \Omega_k$.

The thinned log-Gaussian Cox process likelihood for observed points at locations $\bm{Y} = (s_1, \ldots, s_n)^\intercal$ is
\begin{equation}
\label{lgcp-likelihood}
\pi(\bm{Y}) = \exp\left( |\Omega| -\int\displaylimits_{\bs \in \Omega} \lambda(\bs) g(\bs) \mathrm{d}\bs \right)\prod_{i=1}^n \lambda(\bs_i)g(\bs_i),
\end{equation}
where $|\Omega|$ is the area of the total surveyed region and $\lambda(\bs)$ and $g(\bs)$ both depend on parameter vectors omitted for readability.  

\subsection{Writing the model as a modified Poisson likelihood}

\sloppy The likelihood \eqref{lgcp-likelihood} contains an integral that cannot be solved analytically.  A common approach for fitting log-Gaussian Cox processes in practice is to approximate the likelihood by replacing the integral with a weighted sum.  In this section we describe this approximate likelihood and show how it can be written as a modified Poisson likelihood.  We adapt the approach given in \cite{simpson_going_2016} for a fully observed log-Gaussian Cox process, modified to account for the point transect distance sampling observation process.

To evaluate the integral we use polar coordinates notation $\bs_k(r, \theta) = \bs_k + r\left[\cos\theta, \sin\theta \right]^T$ with $r \in [0, W]$ and $\theta \in [0, 2\pi]$ to represent locations in each sampling unit $\Omega_k$.  In a slight abuse of notation $\bs_k$ denotes the centre of the point transect and $\bs_k(r,\theta)$ describes any location within the point transect.  It should be clear from context which is intended by $\bs_k$.   The thinning function $g_k(\bs_k(r, \theta))$ depends only on $r$ and not on $\theta$ and so we use the shorthand notation $ g(\bs_k(r, \theta)) = g_k(r)$. 

The integral in the likelihood can be simplified using an assumption that $\lambda(\bs)$ is linear within each sampling unit.  This implies that $\lambda(\bs_k(r, \theta)) + \lambda(\bs_k(r, \theta + \pi)) = 2\lambda(\bs_k)$.  Therefore
\begin{align}
\label{eq-linear-intensity}
	\int_0^{2\pi} \lambda(\bs_k(r, \theta))g_k(r)\mathrm{d}\theta &= \int_0^\pi \{\lambda(\bs_k(r, \theta)) + \lambda(\bs_k(r, \theta + \pi) \} g_k(r)\mathrm{d}\theta \nonumber \\
	&= 2\pi \lambda(\bs_k)g_k(r).
\end{align}
We note that this is a relaxation of the traditional assumption in distance sampling that the intensity is constant within each sampling unit.  A similar relaxation is also possible in the case of line transects \citep{yuan_point_2017} and this assumption complements the choice of piecewise linear basis functions used for the GMRF spatial effect (Section \ref{sec-gmrf}).  

It follows that $\int \lambda(\bs)g(\bs) \mathrm{d}\bs = \sum_{k=1}^K 2\pi \lambda(\bs_k) \int_0^W r g_k(r)\mathrm{d}r$ by applying the change of variables formula for integration and substituting in \eqref{eq-linear-intensity}.  Note that this integral now only involves the one dimensional integral with respect to $r$.  For each sampling unit we approximate this integral using a midpoint integration method with $M$ integration locations $r_{k1}, \ldots, r_{kM}$ and associated weights $\alpha_{k1}, \ldots, \alpha_{kM}$.  This gives
\begin{equation*}
	\int\displaylimits_{\bs \in \Omega} \lambda(\bs)g(\bs)\mathrm{d}\bs \approx \sum_{k=1}^K \sum_{j=1}^M \tilde{\alpha}_{kj} \tl(\bs_{kj}) ,
\end{equation*}
where $\tilde{\alpha}_{kj} = 2\pi \alpha_{kj}r_{kj}$ and $\tl(\bs_{kj}) = \lambda(\bs_k) g_k(r_{kj})$.

To simplify notation below we gather all integration weights into the vectors $\tilde{\alpha}_{k} = (\alpha_{k1}, \ldots, \alpha_{kM})^\intercal$ and $\tilde{\alpha} = (\alpha_1^\intercal, \ldots, \alpha_K^\intercal)^\intercal$.  Similarly, let $\tl_k = (\tl(\bs_{k1}), \ldots, \tl(\bs_{kM}))^\intercal$, $\tl_{int} = (\tl_1^\intercal, \ldots, \tl_K^\intercal)^\intercal$, the thinned intensity evaluated at each integration location, and $\tl_{obs} = (\tl(\bs_1), \ldots, \tl(\bs_n))^\intercal$, the thinned intensity evaluated at each observation location.  Then the approximate log-likelihood can be written as
\begin{equation}
\label{approx-log-likelihood}
	\log \pi(\bm{Y}) \approx - \tilde{\alpha}^\intercal \tl_{int} + 1^\intercal\log\tl_{obs}.
\end{equation}
This approximate likelihood can be expressed as a modified Poisson likelihood by letting $\eta = (\tl_{int}^\intercal, \tl_{obs}^\intercal)^\intercal$,
$\alpha = (\tilde{\alpha}^\intercal, 0_{n \times 1}^\intercal)^\intercal$ and constructing a vector of pseudo-observations $z = (0_{KM\times 1}^\intercal, 1_{n \times 1}^\intercal)^\intercal$.  Then the approximate likelihood is
\begin{equation}
\pi(\bm{Y}) \approx C \prod\limits_{i=1}^{KM + n} \eta_i^{z_i}\exp(-\alpha_i\eta_i),
\end{equation}
where $C$ is a constant.  This approximate likelihood is implemented in \texttt{inlabru} as a \texttt{"cp"} likelihood.  

The approach taken here is similar to the Berman-Turner device \citep{baddeley_practical_2000, berman_approximating_1992} that is used to fit a wide variety of point process models using GLM software.  The main difference with our approach is that we do not use the assumption that the locations of observed points form a part of the quadrature scheme.

\subsection{Intensity functions for incomplete data}

In the above, we assume the data are complete records of animal locations.  That is, each observation has a known position $\bs_{k(\bs_i)} = \bs_{k(\bs_i)}(r_i, \theta_i)$.  However, in many distance sampling surveys only the location of the observer and the distance to the observer are recorded.  Data of this type can be analysed within a point process framework by deriving the appropriate intensity function.  We consider the case where $r$ is recorded but not $\theta$.  It follows that the intensity for points at a distance $r$ observed within sampling unit $\Omega_k$ is
\begin{align}
\label{intensity-incomplete}
\tl_k(r) &= \oint\displaylimits_{c_k(r)} \lambda(\bs)g_k(r)\mathrm{d}\bs \nonumber \\
&= 2\pi\lambda(\bs_k)rg_k(r),
\end{align}
where $c_k(r)$ is a circle of radius $r$ centred at $\bs_k$ and the second line follows from change of variables and the assumption of linear intensity within $\Omega_k$.  This intensity differs from the full data case through the $2\pi$  term that accounts for the fact that we do not observe $\theta$ and the additional $r$ term that accounts for the increasing area surveyed at larger distances.  We note that a similar equation is derived from the perspective of a triangular distribution for point transect distance sampling in \cite{buckland_advanced_2004}.  

The log-intensity for detected points is therefore $\log\tl(\bs) = \log 2 \pi r + \log\lambda(\bs) + \log g(\bs)$ and so it is straightforward to account for incomplete location information by including an offset term.  As we noted above, the detection function $g(\bs)$ is non-linear in its parameters and this component of the additive predictor requires a novel approach to parameter estimation.

\section{Iterated INLA}
\label{sec-iinla}

The half-normal detection function depends on the strictly positive parameter $\sigma^2$. Since it is not possible to restrict the range of parameters to be strictly positive within \texttt{R-INLA} this model cannot be fitted using the standard INLA methodology.  Instead, we choose a log link and consider $g(\bs | \phi)$, where $\log\sigma^2 = \phi$. This is a non-linear function of $\phi$ which cannot be fitted using standard GLM methods.  To address this we use a novel approximate-method based on an iterative model fitting scheme. This method is implemented in the \texttt{R} package \texttt{inlabru} which is a wrapper for and an extension of the \texttt{R-INLA} package \citep{lindgren_inlabru_2024}.  Full details of the method can be found in the software paper, here we present a brief overview.  

Let $\eta(\bm{u}) = \log \tilde{\lambda}(\bm{u})$ where $\bm{u}$ is the parameter vector of the predictor (which includes $\phi$ as well as any parameters for fixed and random effects).  Denote by $\bar{\eta}_{\bm{u}_0}$ the first-order Taylor approximation of $\eta(\bm{u})$ at the point $\bm{u}_0$.  That is
\begin{equation*}
\bar{\eta}_{\bm{u}_0} (\bm{u}) = \eta(\bm{u_0}) + \bm{B}_{\bm{u}_0}(\bm{u} - \bm{u}_0),
\end{equation*}
where $\bm{B}_{\bm{u}_0}$ is the derivative matrix of $\eta(\bm{u})$ evaluated at $\bm{u}_0$.  Since $\bar{\eta}_{\bm{u}_0}$ is linear in $\bm{u}$ it is possible to fit an approximate model in INLA by replacing the non-linear $\eta$ with the linear Taylor approximation $\bar{\eta}_{\bm{u_0}}$.   

The question then is how to choose the linearisation point $\bm{u}_0$.  To find an `optimal' linearisation point we use a fixed point iteration scheme.  There are various possible choices to define an `optimal' choice and this affects the properties of the approximate inference method.  Here we describe the criteria used when fitting the model that produces the results presented in this paper.  However, more recently, other options have been added to \texttt{inlabru}, the software package that implements these methods.

Let $\bar{p}_{\bm{v}}$ denote the INLA approximate posterior distribution of the model parameters given the linearised model configuration at linearisation point $\bm{v}$.  New linearisation points are found by via the functional
\begin{equation}
	f(\ol{p}_{\bm{v}}) = (\wh{\bm{\theta}}_{\bm{v}},\wh{\bm{u}}_{\bm{v}})
\end{equation}
where
\begin{equation}
\wh{\bm{\theta}}_{\bm{v}} = \argmax_{\bm{\theta}} \ol{p}_{\bm{v}} ( \bm{\theta} | \bm{y}),
\end{equation}
the posterior mode for $\bm{\theta}$, and
\begin{equation}
\wh{\bm{u}}_{\bm{v}} = \argmax_{\bm{u}} \ol{p}_{\bm{v}} (\bm{u} | \bm{y}, \wh{\bm{\theta}}_{\bm{v}}),
\end{equation}
the joint conditional posterior mode for $\bm{u}$.  This functional defines a new linearisation point as the posterior mode for $\bm{\theta}$ under the linearised model configuration and the conditional mode for $\bm{u}$ given $\bm{\theta}$.  These posteriors are computed automatically during the model fitting using the standard INLA method and so this functional can be evaluated at no extra cost for each fit of the linearised model.

The `optimal' approximate model is defined as a fixed point of this functional.  Given a current choice of linearisation point $\bm{v}$, we estimate $\bar{p}_{\bm{v}}$ and set $\bm{u}_* :=f(\bar{p}_{\bm{v}})$ to use as the new linearisation point.  We iterate this procedure until a fixed point $\bm{v}^*$ is identified within a chosen tolerance such that $\bm{v}^* = f(\bar{p}_{\bm{v}^*})$.

\section{Spatially Structured Random Effect}
\label{sec-gmrf}

This section describes the spatial model for the intensity process.  
As mentioned above, the \akepa{} population exhibits spatial heterogeneity for which there is no known explanatory covariate.  Therefore we use a spatially structured random effect to explain this variation.

Using spatially-structured random effects can be computationally expensive.  Often this is due to parameterisations and approximations that lead to dense prior precision matrices which have an  $\mathcal{O}(k^3)$ cost to factorise for an effect with $k$ basis parameters.  A key approach in computationally efficient methods for spatially structured random effects is the use of sparse Gaussian Markov random field (GMRF) representations of Gaussian random fields (GRFs).  These result in a sparse precision matrix which can be factorised with a cost of $\mathcal{O}(k^{3/2})$.  We use a GMRF representation based on a stochastic partial differential equation approach \citep{lindgren_explicit_2011}.  This representation is constructed by applying finite element methods to solve the SPDE numerically.

Since only the distance to the observer was recorded, and not the exact location of \akepa{}, we used the adjusted intensity given in equation \eqref{intensity-incomplete}.  The log-intensity of animal locations, detected or undetected, is given by
\begin{equation*}
\log \lambda(\bs) = \beta_0 + \xi(\bs)
\end{equation*}
where $\beta_0$ is an intercept parameter and $\xi(\bs)$ is a mean zero GRF with Mat\'ern covariance.  The Mat\'ern covariance function in two dimensions can be written as 
\begin{equation}
C(\bs_1,\bs_2) = \frac{2^{1-\nu}}{4\pi\kappa^2\tau^2\Gamma(\nu)}(\kappa \|\bs_1-\bs_2\|)^{\nu}K_\nu(\kappa \|\bs_1-\bs_2\|)
\end{equation}
where \(\nu, \kappa, \tau\) are parameters and \(K_{\nu}\) is the modified Bessel function of the second kind.  The three parameters are not simultaneously identifiable \citep{zhang_inconsistent_2004} and it is conventional to assume a value for $\nu$ which specifies the mean-square differentiability of the process.  We set $\nu = 1$ which is the default value in \texttt{R-INLA}.

We use a GMRF representation of $\xi(\bs)$ following the approach of \cite{lindgren_explicit_2011} based on specifying $\xi(\bs)$ via a SPDE.  We define a finite element mesh with $L$ nodes and associated piece-wise linear basis functions $\phi_1, \ldots, \phi_L$. The GRF is represented as $\xi(\bs) = \sum_l \beta_l \phi_l(\bs)$.  The parameters $\beta_1, \ldots, \beta_L$ form a GMRF with sparse prior precision matrix $\bm{Q} = \frac{1}{\tau^2}\left(\kappa^4\bm{C} + 2\kappa^2\bm{G_1} + \bm{G_2}\right)$ where $\bm{C}$, $\bm{G_1}$, $\bm{G_2}$ are all sparse matrices (\cite{blangiardo_spatial_2013}, Equation 6.19). The parameters $\tau$ and $\kappa$ control the shape and rate of decay of the Mat\'ern covariance function as distance between locations increases. We use a finite element mesh with 3748 nodes defined over the entire study region and extended over a buffer region to avoid the effects of boundary conditions within the region of inference.

In order to specify priors on the Mat\'ern covariance we use a reparameterisation of $\kappa$ and $\tau$ to a range and variance parameter.  When $\nu = 1$ and the domain is two dimensional then the reparameterisation is $\rho = \sqrt{8} / \kappa$ for the range and $\sigma^2 = 1 / (4\pi\kappa^2\tau^2)$ for the marginal variance (\cite{blangiardo_spatial_2013}, p196).  This parameterisation is used to set penalised complexity priors \citep{simpson_penalising_2017} on $\rho$ and $\sigma^2$ which allow the GRMF effect to shrink towards zero.  For the Mat\'ern field, the base model is the limiting case with $\sigma^2 \rightarrow 0$ and $\rho \rightarrow \infty$, which defines a random field that is almost surely zero everywhere.  The purpose of penalised complexity priors is to place sufficient prior probability on a simple model to allow the random effect to be essentially `turned off' if the model component is not supported by the data.  To specify penalised complexity priors on the SPDE effect we set $\mathbb{P}(\sigma > 2) = 0.01$ and $\mathbb{P}(\rho < 130) = 0.01$.  The value of 130 for the range parameter was selected based on the minimum distance between sampling locations.  

The SPDE approach can at first appear to be fundamentally different  other approaches such as penalised regression splines.  However, the two methods are closely related and the GRF model component in our model plays a similar role to a penalised smoothing spline on space.  \cite{yue_bayesian_2014} show how spline models can be viewed through the perspective of SPDEs and \cite{miller_UnderstandingStochasticPartial_2020} do the reverse to show how to implement the Mat\'ern SPDE as a penalised spline model in \texttt{mgcv} \citep{wood_gam_2017}.

\section{Results}
\label{sec-results} 

The model fits in roughly 40 to 60 seconds on a laptop with 10 Gb RAM and a 2.50 GHz CPU when INLA is run using the `empirical Bayes' option which does not incorporate uncertainty in hyper parameters.  The model fits in a few minutes in the full INLA mode, including hyper parameter uncertainty.  We suggest using the `empirical Bayes' mode for model development and full INLA on a smaller subset of candidate models.  

The predicted mean of the posterior intensity field is shown in \autoref{fig:intensity-mean-cv}A along with a map of the coefficient of variation (CV) (\autoref{fig:intensity-mean-cv}B) and standard deviation of the posterior intensity field (\autoref{fig:intensity-mean-cv}C) on a regular prediction grid with each prediction cell area approximately 1.7 hectares.
\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.525]{figures/intensity_mean_cv_sd.png}
		\caption{The A) mean, B) CV and C) SD of the posterior intensity field.  Units are per m$^2$.  The colour scale is different for each panel.}
		\label{fig:intensity-mean-cv}
	\end{center}
\end{figure}
This shows a region of high intensity in the south and much lower intensity in the north, agreeing with a standard two-stage analysis of the same data \citep{camp_dsm_2020}.  The CV plot shows that the CV in the posterior intensity field is lower in areas with greater sampling effort and higher intensity.  There is a clear indication of preferential sampling with more survey effort in the south, where densities are higher, compared to the north.  In the north, estimated intensities are lower, which also contributes to larger CV values and makes the CV map hard to interpret.  The standard deviation map shows stronger overall posterior variability in the south where intensity is larger, most likely due to the assumed log-normal relationship between the random field and the Poisson rate parameter.  

We also map the lower and upper quantiles corresponding to a 95\% credible interval for each prediction location (Figure \ref{fig:intensity-quantiles}).  As we discuss below, these quantiles are independent summary statistics of the posterior intensity field at each prediction location.  
\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.525]{figures/intensity_quantiles.png}
		\caption{The predicted posterior intensity quantiles:  A) 0.025 quantile B) 0.975 quantile.  Both plots use the same colour scale.}
		\label{fig:intensity-quantiles}
	\end{center}
\end{figure}

The posterior detection function (\autoref{fig:det-matern}) shows that detectability drops to just under 0.25 at the maximum observable distance of 58 metres and also broadly agrees with a two-stage analysis.
\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.525]{figures/detfn_and_matern.png}
		\caption{A) Posterior half-normal detection function. B) Posterior Mat\'ern correlation function.  The black line is the mean posterior estimate and the grey shaded area is 95\% credible interval in both plots}
		\label{fig:det-matern}
	\end{center}
\end{figure}
The posterior Mat\'ern correlation function is shown in \autoref{fig:det-matern}; the grey regions show the 95\% credible interval.  We note that this correlation function shows positive correlation even at distances of 10,000 metres, wider than the full length of the study region (approximately 8,000 metres).  This is because the correlation function is defined on the log-intensity scale.  On the intensity scale the empirical range of correlation is shorter.

To evaluate the ability of the SPDE effect to capture the spatial heterogeneity in the observed data we generated 1,000 point patterns using the posterior intensity field and thinned them with the posterior detection function to create 1,000 simulated datasets to compare with the observed data.  We calculated the pairwise distances between all observations for each of these datasets and compared the frequency of pairwise distances with those in the observed data.
\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.6]{figures/post_pp_distances.png}
		\caption{Boxplots of the frequency of pairwise distances (tick mark values for end of each bin) based on 500 simulated datasets from the posterior predictive distribution.  Red circles indicate the frequency of pairwise distances in the observed data.}
		\label{fig:post-pp-distances}
	\end{center}
\end{figure}
Figure \ref{fig:post-pp-distances} shows that the SPDE effect broadly captures the spatial clustering in the observed data.  There is some evidence of under-predicting the strength of the clustering at shorter distances between 1,000 and 2,500 m, with the simulated data showing some evidence of negative bias.  This could be due to over-smoothing in some areas which can happen if using a stationary model.  Large areas of the study region having low density, which has a larger correlation range than higher density areas, and so the effect will average between these. 

Figure \ref{fig:post-pp-distances} is similar in spirit to Ripley's $K$-function \citep{ripley_SecondorderAnalysisStationary_1976}, which is a common approach to investigating spatial structure in point patterns.  The pairwise distances in the observed data is a function of spatial heterogeneity as well as the spatially restricted sampling scheme.  Other methods of comparison could also be considered such as the average difference between predicted and observed counts at each point transect.  Working with posterior predictive datasets is a flexible approach to model evaluation that allows for innovative methods of comparison with observed data that can focus on particular features of the model.

To plot the posterior abundance estimate for the \akepa{} in Hakalau we use a Monte Carlo method based on sampling realisations of the posterior intensity field.  Let $n$ denote the abundance of the population within the region of interest and $N = \int_{\Omega}\lambda(\bs)\mathrm{d}\bs$ its corresponding random variable within our Bayesian framework.  Integrating the mean of the posterior intensity field provides a point estimate for the abundance, i.e. the expected abundance.  To generate a full posterior estimate for abundance we approximate the posterior $\pi(N | \bm{Y})$ by taking $m$ Monte Carlo samples of the posterior intensity field, $\lambda^{(1)}, \ldots, \lambda^{(m)}$ and approximate the posterior for the abundance as $\pi(N | \bm{Y}) \approx 1 / m \sum_{i=1}^m \pi (N | \lambda = \lambda^{(i)}, \bm{Y})$. Each $\pi(N | \lambda = \lambda^{(i)}, \bm{Y})$ is a Poisson probability mass function with rate parameter $\int_{\Omega}\lambda^{(i)}(\bs)\mathrm{d}\bs$. 
\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.525]{figures/N_posterior.png}
		\caption{Posterior abundance.  Grey area marks two Monte Carlo standard errors above and below the mean}
		\label{fig:realized-abundance-posterior}
	\end{center}
\end{figure}

\autoref{fig:realized-abundance-posterior} shows the approximate posterior for $N$ with $m = 20,000$.  This allows us to estimate the probability for any specific value of realised abundance $n$ which may be of interest to conservation managers.  This approach can also be used to generate credible intervals and other posterior summaries of interest. 

The abundance estimates cannot be directly compared to the results in \cite{camp_dsm_2020} since their two-stage model also includes a temporal correlation and we include an area of Hakalau that the authors excluded.  Converting the above abundance estimates to density per hectare for the whole study region allows for some comparison with Figure 2 in \cite{camp_dsm_2020} which suggests that \akepa{} density was roughly between 0.5 and 1.5 birds per hectare in 2002 (considering both the design-based estimate and the spatio-temporal GAM estimate).  In our analysis we find a credible region of roughly 0.9 to 1.7 birds per hectare, which is slightly different but overlaps significantly with the results in \cite{camp_dsm_2020}.

An attractive feature of our Bayesian one-stage model is that, by basing model outputs on posterior Monte Carlo samples, all the outputs presented in the above, the summaries of the random field as well as the posterior abundance, incorporate the uncertainty in the detection model in a natural way.  There is no additional step required to incorporate detection function uncertainty beyond working with samples from the joint posterior.

\subsection{Limitations of mapped summaries}

Our presentation of the results above is broadly consistent with approaches taken in the species distribution modelling literature, although maps of predictive uncertainty (Figures \ref{fig:intensity-mean-cv} and \ref{fig:intensity-quantiles}) are not always provided.  It is common to see maps of point estimates (e.g. a map of expected density) without any accompanying communication of uncertainty.  It is also common to report a point estimate of the expected abundance along with uncertainty in the point estimate.  However, uncertainty in a point estimate will have lower variance than the variance of the posterior random variable.  For this reason we chose to present the full abundance posterior in \autoref{fig:realized-abundance-posterior} as opposed to uncertainty of a `best guess' for abundance.  Our intention in this section is to highlight further limitations with the model outputs presented above and to suggest ways to address these limitations. 

The most common method to communicate uncertainty in maps of animal density is to produce maps of some measure of predictive uncertainty, such as the standard deviation or CV \citep{fuller_novel_2018, vallejo_responses_2017,bradbury_mapping_2014}.  These can be derived from the posterior predictive distribution for the model in a Bayesian framework and bootstrapping in a maximum likelihood context.  Another approach is to map quantiles or the probability of exceeding certain thresholds at each prediction location \citep{russell_avoidance_2016, wilson_hierarchical_2010}.  In Section \ref{sec-results}, we present maps of the CV, standard deviation, and the 0.025 and 0.975 quantiles of the posterior intensity field (Figures \ref{fig:intensity-mean-cv}B, \ref{fig:intensity-mean-cv}C, \ref{fig:intensity-quantiles}A, and \ref{fig:intensity-quantiles}B, respectively) that are all intended to communicate uncertainty in the estimate of the \akepa{} spatial distributions.  Whilst such maps that summarise spatial predictions are useful, they all mask certain properties that may be important when communicating the results of the analysis. 

A map showing the posterior predicted mean across the study region (Figure \ref{fig:intensity-mean-cv}A) is often the key output of a species distribution model.  However, the posterior mean will always be smoother than realisations of the field itself, highlighting that even this relatively innocuous summary statistic can mask important features of the random field.  \autoref{fig:intensity-realizations} shows three such realisations from the posterior intensity field.  Note that each realisation has a finer-grained spatial structure than is shown in the posterior mean (\autoref{fig:intensity-mean-cv}A).  Our interpretation is that the clustering of animals is stronger than might be expected if we only looked at the map of the posterior mean.
\begin{figure}[!htb]
	\includegraphics[scale=0.525]{figures/intensity_realized.png}
	\caption{Three realizations of the posterior intensity field}
	\label{fig:intensity-realizations}
\end{figure}

For model evaluation we recommend plotting multiple realisations of the posterior field as these will more closely resemble the spatial structure of the observed data and thus what ecologists might encounter in the field.  The mean can give a sense of homogeneity, particularly in the high density area in the south, when compared to realisations of the mean.  Presenting multiple realisations, perhaps as an animation, is also an effective way to communicate uncertainty. \cite{bowman_GraphicsUncertainty_2019a} provide an interpolation method that preserves the mean and covariance structure of realisations that smoothly interpolates between realisations.  This avoids abrupt changes that can occur when animating the raw realisations.  

The CV map (\autoref{fig:intensity-mean-cv}B) is also intended to communicate uncertainty.  However, CV values will generally be higher in regions of low predicted intensity, particularly if the posterior standard deviation is relatively consistent across the study region or positively correlated with the intensity.  Higher CV values in Figure \ref{fig:intensity-mean-cv}B represent areas of lower intensity but not necessarily higher uncertainty.  However, there is also variable sampling effort within the study region, with higher CV values in the region with lower effort.  It is not clear what impact this has on the CV values and this makes the map hard to interpret.

The standard deviation (SD) map (\autoref{fig:intensity-mean-cv}C) shows spatially varying SD values also intended to indicate uncertainty.  However, care should be taken as to what the mapped values imply in the context of a given analysis.  A default colour scale will nearly always show some spatial variation in uncertainty, with some regions of relatively high and low uncertainty.  However, whether these relative differences matter is dependent on the overall context of the analysis.  Some levels of variability may be acceptable in some contexts and unacceptable in others.

The SD values also reflect a modelling assumption rather than variability due to, say, varying survey effort.  The SD is linked to the predicted mean by the assumed log-Gaussian relationship.  If X is normally distributed with mean $\mu$ and variance $\sigma^2$ then $Z = \exp(X)$ has a mean-variance relationship given by $\text{Var}(Z) = \exp(\sigma^2 - 1)\mathbb{E}(Z)^2$. Therefore the SD map will generally show a pattern similar to the mean intensity map (Figures 2A and 2B).  Since this relationship is the result of a modelling assumption and not necessarily reflective of the detectability of animals or survey effort.  It should be noted however, that this modelling assumption affects uncertainty quantification for all outputs based on the posterior intensity field, not just the SD map.

The quantile maps (Figure \ref{fig:intensity-quantiles}) are also difficult to interpret. The temptation is to perceive the maps as showing possible intensity surfaces that could have produced the observed data. One possible intensity surface (0.025 quantile map) that signifies a kind of lower bound on abundance and another surface (0.975 quantile map) that signifies higher abundance.  However, presenting these quantiles together in a single map obscures the fact that it is vanishingly unlikely for the random field to \textit{simultaneously} achieve the 0.025 or 0.975 quantiles at all prediction locations.  A similar problem holds for maps of the marginal probability of exceeding a threshold at each prediction location.  

Presenting independent quantiles jointly in a single image is risky.  These caveats make the map difficult to use for most non-statistically trained audiences and even trained statisticians may misinterpret these quantile maps.  To demonstrate the possible consequences of this we (incorrectly) treat the lower and upper quantile plots as though they are intensity functions and integrate them to obtain an expected abundance estimate of approximately 2,900 for the 0.025 quantile map and 10,700 for the 0.975 quantile map.  A naive (and tempting) interpretation of these numbers is as lower and upper limits of the 95\% credible interval for abundance. However, these abundance estimates are not supported by the posterior for abundance (\autoref{fig:realized-abundance-posterior}).  This shows that the tendency to interpret these maps as showing possible intensity surfaces can lead to interpretations that are inconsistent with the very model that generated the maps.

We conclude that, although all useful in their own way, each of the mapped summaries of the posterior intensity field suffer from some weaknesses, whether through masking certain properties of the random field or through being difficult or impossible to interpret. In the following section we suggest an approach that avoids some, but not all, of the pitfalls above.

\subsection{Excursion sets and excursion functions}

One solution to the problem of interpreting quantile and exceedance probability maps is to use methods that explicitly consider the \textit{joint} probability of events across prediction locations, as opposed to the \textit{marginal} probability at each location. The approach taken here requires that we decide, \emph{a priori}, on relevant values of the process and acceptable levels of uncertainty that are suitable given the context and aims of the analysis.  These values can then be used to construct summary maps that consider joint events across prediction locations.  

We demonstrate this perspective using excursions sets and excursion functions \citep{bolin_excursion_2015}. By choosing acceptable levels of uncertainty, these methods avoid the issue of the default colour scale for the SD and CV maps which may potentially affecting our interpretation of results.  Excursion sets and excursion functions are also based on the joint probability of events across a set of locations.  For this reason they avoid the interpretability issues of the quantile maps.

We give the technical definition of excursion sets and functions below, using the same notation as \cite{bolin_excursion_2015}.  For readers unfamiliar with these methods, the notation can take some getting used to.  However, the precise mathematical definitions are useful when it comes to interpreting these methods.  We try to, as much as possible, give an informal explanation alongside the mathematical description.

The positive excursion set with level $u$ for a function $f(\bs)$ with domain $\Omega$ is $A_u^{+}(f) = \{ \bs \in \Omega ; f(\bs) > u \}$, i.e. the set of all locations in $\Omega$ where $f$ exceeds a threshold value $u$. For a random field, $\lambda(\bs)$, the positive excursion set with level $u$ and probability $1 - \alpha$ is
\begin{equation*}
E_{u,\alpha}^{+}(\lambda) = \argmax_{D}\{\lvert D \rvert : \mathbb{P}\left[D \subset A_u^{+}(\lambda)\right] \geq 1 - \alpha \} .
\end{equation*}
Note that $A_u^{+}(f)$ specifies a set of locations for which a function $f(\bs)$ exceeds a threshold value $u$ for \textit{every location} in the set. Therefore, the positive excursion set $E_{u,\alpha}^{+}(\lambda)$ is the \textit{largest} such set of locations for which \textit{realisations} of $\lambda(\bs)$ exceed the threshold $u$, \textit{simultaneously} for all locations in the set, with probability $1-\alpha$.  Note that we must decide on relevant choices for $u$ and $\alpha$ given the aims and context of the analysis.  Negative excursion sets are similarly defined by considering the probability of being below a threshold value.  Contour uncertainty can also be defined as the set difference between positive and negative excursion sets \citep{bolin_excursion_2015}.

Excursion sets can be estimated by considering candidate sets for $D$ of increasing size and a sequential integration scheme to estimate the required probabilities in a computationally efficient way.  A full description of the methods is given in \cite{bolin_excursion_2015} and a software implementation in the \texttt{excursions} package \citep{bolin_calculating_2018}.  

\autoref{fig:excursions}A shows the positive excursion set with a level corresponding to 1 bird per hectare with probability 0.95 (hence $\alpha = 0.05$).  This figure can be interpreted in a natural way as the largest region for which the intensity is greater than 1 bird per hectare for every location within the region, with probability 0.95. 
\begin{figure}[!htb]
	\includegraphics[scale=0.5]{figures/excursions.png}
	\caption{A) The positive excursion set with a level corresponding to 1 bird per hectare and probability 0.95.  B) The positive excursion function with a level corresponding to 1 bird per hectare.  The scale shows the probability values $1-\alpha$.}
	\label{fig:excursions}
\end{figure} 
This map could be used to define, for example, a `core region' for the \akepa{} population, with particular conservation importance.  Crucially, this map depends on a clear mathematical description of what a `core region' actually means in a statistical sense.  While any particular definition would be up for debate, the advantage is that the statistical methodology is taken as close as possible to the aims of the analysis.  Often a map of species density will be interpreted informally in many different ways (one of which is identifying hotspots for example).  Here we present an example of how a clear statistical definition can be used to produce a map that incorporates relevant definitions and uncertainties, and can be interpreted clearly.  

To visualise how such excursion sets change with different levels of uncertainty we can use the excursion function $F_u^{+}(\bs) = \sup \{1 - \alpha ; \bs \in E_{u,\alpha}^+ \}$.  This defines, for each location, the largest possible probability $1 -\alpha$ for which that location would be in the excursion set defined using probability $1 - \alpha$.  I.e.  if we allow greater uncertainty, this function shows which locations would be included in the excursion set.    

The excursion function with a level corresponding to 1 bird per hectare is shown in \autoref{fig:excursions}B.  It is clear from the figure that regions close to the edge of the excursion set with $\alpha = 0.05$ would be included if the $\alpha$ value were allowed to increase slightly.  Similarly, the core of the high density region seems to exceed 1 bird per hectare even for $\alpha$ levels close to zero.  There is a region to the north of the main population that would be included in the positive excursion set for 1 bird per hectare if the probability were allowed to be lower, around 0.5.  However, for regions in the north there is essentially no probability level for which those locations would be included.  This map could be used to identify, for example, secondary areas of potential importance beyond the core population that could be investigated further.

We chose the threshold of 1 bird per hectare and an error probability of 0.05 to demonstrate the approach.  However, multiple values for each of these can be considered and we imagine that, in most contexts, there would be value in considering various sets of thresholds and uncertainty levels.


\section{Discussion}
\label{sec-discussion}

We have presented a new approach to analysing point transect distance sampling data in a Bayesian setting.  We chose to do this in a relatively simplified setting, considering a single year of data, with no covariate effects and using a GRF to explain spatial variation in density.  There are several natural extensions to the model.  Spatio-temporal models can also be fitted using \texttt{R-INLA}, which would allow multiple years of data to be modelled jointly, as was the case in \cite{camp_dsm_2020}.  Another extension is to develop the observation process model by considering other detection functions or including covariates, for example.  Factors such as weather conditions, observer expertise, animal behaviour and morphological traits are likely to affect detectability.  Future research should investigate the degree of complexity that can be well-approximated by the iterated INLA approach.

The iterated INLA inference procedure has the potential to be applied to other non-linear model components that arise spatial statistics.  We note two promising areas within the field of spatial ecology that highlight this potential: 

\begin{itemize}
	\item \textbf{Selectivity analysis} In surveys of the marine environment, the size, length and weight of fish affects the likelihood of being caught in a trawl net.  The probability of capture is typically modelled as a logistic function with parameters that depend on morphological traits \citep{herrmann_understanding_2016, madsen_selectivity_2007, galbraith_demersal_1994}.  This function is analogous to the detection function in distance sampling models.  Our framework could allow, for example, the joint modelling of selectivity and spatial data.
	\item \textbf{Functional responses} The concept of a `functional response' captures the idea that the overall abundance of a resource or risk will affect a species' response to it \citep{holling_some_1959}.  These varying responses can be described mathematically using parametric equations that have the desired properties, e.g. an increasing function with a horizontal asymptote, to capture the notion of diminishing returns.  Such non-linear functions could be incorporated within our framework.  This flexibility in specifying model components could also be more widely applicable in areas such as public health and spatial epidemiology, where responses to conditions may suitably be modelled using non-linear relationships.
\end{itemize}
There are no doubt many more application areas that could make use of the additional flexibility that comes with allowing non-linear predictors.

The popularity of using INLA for spatial modelling has grown, in large part, due to the computational efficiency of the approach.  However, this efficiency comes at the cost of reduced flexibility in model specification over, say, a more general probabilistic programming languages such as \texttt{JAGS} \citep{plummer_jags_2017} or \texttt{Stan} \citep{stan_Rstan_2020}.  The iterated INLA approach allows a wider class of models to be considered whilst retaining much of the computational benefits of INLA.  In addition to computational efficiency, there are some features of INLA that are not generally available in other packages, such as: (i) the ability to model using GRFs directly on the sphere, avoiding projecting to $\mathbb{R}^2$ \citep{lindgren_explicit_2011}; (ii) GRFs that account for complex barriers such as coastlines and islands, to avoid inappropriately smoothing across these \citep{bakka_NonstationaryGaussianModels_2019}; and (iii) support for joint likelihood models, allowing modelling of, for example, marked point processes \citep{illian_FittingComplexEcological_2013}, and combining multiple data sources.  These approaches, and many others we have not mentioned, that are implemented in INLA, can now readily be incorporated into distance sampling analyses, as well as broader spatial ecology and spatial statistics applications. 

\section*{Data Availability} 

Hawaii Akepa (Loxops coccineus) point-transect distance sampling data were provided by U.S. Fish and Wildlife Service, Hakalau Forest Unit of the Big Island National Wildlife Refuge Complex. The 2002 survey data are available from the U.S. Geological Survey: \url{https://doi.org/10.5066/P9Q9UXMZ} \citep{camp_datarelease_2002}.  The time data for 1987-2017 is also available  available from the U.S. Geological Survey: \url{https://doi.org/10.5066/P98IO297} \citep{camp_datarelease_all}

Code to reproduce the figures and results in this paper are available in a git repository and can be accessed at \url{https://github.com/ASeatonSpatial/point-transects-paper/}.

\section*{Acknowledgements}

We are grateful to the many U.S. Fish and Wildlife Service staff and volunteers who helped collect the data through the \hawaii Forest Bird survey. We thank Steve Buckland for helpful comments on an early draft.  Any use of trade, firm, or product names is for descriptive purposes only and does not imply endorsement by the U.S. Government.

\clearpage
\bibliographystyle{rss}
\bibliography{paper}

\end{document}
