\documentclass{stylefile16/statsoc}
\usepackage[a4paper]{geometry}   % otherwise statsoc class doesn't compile to A4 correctly

%\usepackage{setspace}
%\doublespacing

\usepackage[hidelinks]{hyperref} % auto detect ref type
\usepackage{natbib}
\setcitestyle{stylefile16/rss}

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{caption}
\usepackage{textcomp}    % for Hawaii characters

% shortcuts
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\T}{\intercal}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\bS}{\mathbf{S}}
\newcommand{\bQ}{\mathbf{Q}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bm}{\boldsymbol}  % bold maths symbols
\newcommand{\tl}{\tilde{\lambda}}   % thinned little lambda
\newcommand{\tL}{\tilde{\Lambda}}  % thinned big lambda

% RJC 09/08/2019 Added shortcuts for Hawaiian words
\newcommand{\akepa}{\textquotesingle\={a}kepa}  % adds Hawaiian diacritical marks
\newcommand{\Akepa}{\textquotesingle\={A}kepa}  % adds Hawaiian diacritical marks
\newcommand{\hawaii}{Hawai\textquotesingle i}   % adds Hawaiian diacritical marks
\DeclareMathOperator*{\argmax}{arg\,max}  % * means _ puts thing beneath operator

\title[One-stage point transect distance sampling using iterated INLA]{One-stage point transect distance sampling using iterated integrated nested Laplace approximations}

\author[Andrew E. Seaton {\it et al.}]{Andrew E. Seaton}
\address{Centre for Research into Ecological \& Environmental Modelling and School of Mathematics \& Statistics, 
	University of St Andrews, 
	St Andrews,
	UK}
\email{aes22@st-andrews.ac.uk}

\author{Janine B. Illian}
\address{School of Mathematics and Statistics, University of Glasgow, Glasgow, UK}

\author{Finn Lindgren}
\address{School of Mathematics, University of Edinburgh, Edinburgh, UK}

\author{Richard J. Camp}
\address{U. S. Geological Survey, Pacific Island Ecosystems Research Center, P.O. Box 44, \hawaii{} National Park, HI 96718, U.S.A.}

% seems like this document class uses short author from the last author
% macro in the preamble?  
\author[Andrew E. Seaton \textit{et al.}]{Steve J. Kendall}
\address{U. S. Fish and Wildlife, Big Island National Wildlife Refuge Complex, 60 Nowelo St., Suite 100, Hilo, HI  96720, U.S.A.}

\begin{document}

\begin{abstract}
Distance sampling methods aim to estimate the size and spatial distribution of populations of wild animals.  Here we present an analysis of point transect distance sampling data collected on an endangered tropical forest bird.  We consider a workflow from model specification, inference method, model evaluation and communication of results, at each stage discussing the statistical challenges involved and our strategies to address them.  We take a point process perspective on point transect data, viewing observations of birds as a thinned log-Gaussian Cox process with a spatially structured random effect describing the spatial distribution of animals specified via a computationally efficient Gaussian Markov random field approximation to Gaussian random field \citep{lindgren_explicit_2011}.  

We use a novel approximate Bayesian inference approach based on iterated fitting of latent Gaussian models using integrated nested Laplace approximations (INLA) \citep{rue_approximate_2009} to account for non-linear model components and jointly estimate detectability and spatial distribution, a process that is usually separated into two models.  Outputs from the model are based on samples from the joint posterior of all model parameters and so naturally incorporate uncertainty due to detectability, a key advantage of the one-stage Bayesian approach.  We discuss limitations of methods to represent uncertainty in mapped estimates of species distributions and advocate for the \textit{a priori} selection of relevant thresholds and uncertainty levels by using excursions methods \citep{bolin_excursion_2015}.

We present an example of a computationally efficient one-stage Bayesian approach to analysing distance sampling data.  However, the inference method presented is general, flexible and applicable in a wide range of areas in statistics beyond modelling species distributions.

\end{abstract}

\keywords{Distance sampling, Species distribution modelling, Estimating abundance, Stochastic partial differential equations, Integrated nested Laplace approximation, SPDE approach}

\section{Introduction}

The estimation of the size and spatial distribution of wild populations of animals is a critical objective within ecology and conservation \citep{schwarz_estimating_1999}. Here we present an analysis of wildlife survey data collected on a critically endangered \hawaii{}an forest bird that aims to meet this objective.  The \hawaii{} \akepa{} (hereafter \akepa{}; \textit{Loxops coccineus}; nomenclature according to \citealp{usfws_akepa_1970}) is an endemic species whose population declined dramatically during the 20th century  \citep{usfws_revised_2006, judge_akepa_2018}.  The remaining population is the focus of sustained conservation efforts and monitoring is required to inform decision-makers about changes in the overall abundance and spatial distribution.  This information is critical when decisions about conservation strategies are made.  However, estimating the abundance and spatial distribution of wild populations of animals presents many statistical challenges.

First, as in many ecological surveys, it is impossible to undertake a full census (i.e. the complete enumeration of all individuals within a defined study region).  The existing population numbers in the thousands and lives in dense tropical forest where logistical and ecological challenges mean a census is not feasible.  For this reason, a monitoring survey must sub-sample appropriately in space and time.  For the \akepa{} this takes the form of the \hawaii Forest Bird Survey (HFBS) \citep{scott_HFBS_1986}, which is a large-scale, quantitative survey of Hawaiian forest birds.  Annual surveys of the \akepa{} study-region consist of a number of point transects located along randomly located line transects.

Second, even at surveyed locations, the detectability of animals is unknown.  The \akepa{} survey estimates detectability using a point transect distance sampling approach \citep{buckland_distance_2015} where, for each observation, the distance to the observer is recorded.  The probability of detecting a bird is modelled using a parametric detection function that decays with increasing distance.  The detection function parameters are estimated from the observed distances by assuming the true density is uniform with respect to distance and attributing deviations from uniformity to imperfect detectability. The combination of spatio-temporal subsampling and unknown detectability means statistical methods to analyse distance sampling data must model a complex observation process alongside the spatial distribution of animals.  

Third, a key aim of the analysis is to predict animal density at unsurveyed locations.  If animal density is modelled using spatial covariates then the covariate effects estimated in the surveyed region can be extrapolated to unsurveyed location.  However, in many ecological contexts there can be good reason to believe there are drivers of the spatial distribution for which we have no explanatory covariates available or for which, in principle, no covariate could be constructed (e.g. the `sociality' of the species).  For the \akepa{} data, one example of an unexplained driver of the spatial distribution is a north-south gradient for which no straightforward explanatory cause has been found \cite{camp_dsm_2020}.  From a statistical perspective, this heterogeneity that cannot be explained by available covariates suggests the inclusion of spatially structured random effects in the model.  Such effects require a careful consideration of the model structure and inference methods to ensure that model fitting remains computationally feasible.

Lastly, the above challenges mean the resulting statistical model is necessarily complex. It is therefore challenging to communicate the results of the analysis to non-statistically trained audiences.  The \akepa{} data is collected with the clear objective of monitoring the population and informing conservation management decisions.  These decisions will be taken by stakeholders with a range of statistical expertise.  This final step of communicating results should therefore be considered with as much care as the rest of the analysis.  This requires the input of statisticians to ensure uncertainty is appropriately captured and communicated in the key outputs of the analysis upon which decisions will be based.  In particular, in the context of species distribution modelling, we note the challenge of communicating uncertainty in maps of predicted animal density.

We present an analysis that addresses these statistical challenges by using the following approaches:

\begin{enumerate}[(a)]
	\item A spatial point process perspective on point transect distance sampling and representing the detection model as a thinning of a point processes.
	\item A one-stage approximate Bayesian approach to inference based on repeated model fits using integrated nested Laplace approximations (INLA) \citep{rue_approximate_2009}.  This allows for the simultaneous estimation of the spatial distribution and detectability of animals.
	\item A computationally efficient Gaussian Markov random field (GMRF) spatially structured random effect specified through a stochastic partial differential equation (SPDE) approach \citep{lindgren_explicit_2011} to account for unobserved drivers of the spatial distribution.
	\item A discussion on model evaluation and communication of results that takes advantage of the one-stage approach by sampling from the joint posterior of all model parameters. We advocate for excursions methods \citep{bolin_excursion_2015} as a way to handle uncertainty in spatial predictions of density.  
\end{enumerate}

We demonstrate several novel contributions to the problem of species distribution modelling under unknown detectability.  This is, to the best of our knowledge, the first analysis of point transect distance sampling data using a point process perspective.  This requires a modified intensity function that accounts for incomplete location information for animal sightings.  This is also the first application of a novel approximate Bayesian inference method to estimate the detection function jointly with the spatial model.  This inference method is readily generalisable to other applications beyond distance sampling models.  As such, this analysis will be of interest to the broad applied statistics community in general, as well as those specifically interested in modelling species distributions.

% Update to section refs
The rest of the paper proceeds as follows:  Section \ref{sec-study-design} describes the \akepa{} study region and survey design; Section \ref{sec-ds-pp} reviews current approaches to distance sampling and presents the point process perspective; Sections \ref{sec-iinla} and \ref{sec-gmrf} describe the iterated INLA fitting procedure and the GMRF random effect; and Sections \ref{sec-results} and \ref{sec-comms} present the results of the analysis and discuss model evaluation and communication.


\section{Study design}
\label{sec-study-design}

The \hawaii{} \akepa{} is an internationally and federally endangered Hawaiian honeycreeper (\citealp{usfws_akepa_1970, birdlife_akepa_2016}) that is endemic to \hawaii{} Island, USA.  Large-scale, quantitative surveys of Hawaiian forest birds and their habitat commenced in the mid-1970s through the HFBS \citep{scott_HFBS_1986}. Information from the HFBS is used to update the listing and delisting of endangered species, and establish preserves that coincided with native bird hotspots, including Hakalau Forest National Wildlife Refuge on \hawaii{} Island (hereafter Hakalau).  Hakalau is the first wildlife refuge established with the primary purpose to protect and manage native forests for the conservation of threatened and endangered bird and plant species. Due to its broad-scale coverage and robust design, the HFBS has become an invaluable dataset used to determine changes in bird species distributions, population sizes and trends in density patterns over time.

During the 20th century, the \akepa{} population declined dramatically due to habitat modification \citep{scott_HFBS_1986, pratt_avifaunal_1994},  mosquito-transmitted avian diseases \citep{pratt_avifaunal_1994, atkinson_wildlife_1995}, introduced predators \citep{lepson_akepa_1997}, and food resources competitors \citep{lepson_akepa_1997}. \Akepa{} has a global abundance of approximately 16,200 (95\%CI 10,000\textendash25,200) birds that is now restricted to five spatially distinct populations \citep{judge_akepa_2018}. Hakalau supports the largest remaining distinct \akepa{} population which, in 2012, was estimated at more than 11,000 birds \citep{camp_statespace_2016}. Maintaining and expanding the \akepa{} population at Hakalau is a primary conservation concern. Unbiased and precise abundance estimates are therefore required by land and resource managers for the purposes of evaluating management actions and developing future management plans.

\subsection{Study area and survey design}

Hakalau was established in 1985 to conserve 15,390 ha of montane forest habitat for native forest birds and rainforest plants. Annual forest bird surveys were initiated in 1987 to determine the population status and track trends in abundance. Survey points were established along 14 line transects following a systematic, random design with point transects located approximately 150m apart on line transects located either 500m or 1,000m apart. We limit our study area to the open-forest and closed-forest strata of Hakalau (\autoref{fig:2002studyareapointspt}), an extension of the area considered in \cite{camp_population_2010, camp_statespace_2016}, who omitted the closed-forest stratum because it was not sampled in the early years of the surveys.  For our analysis, we use data from a later year in which the closed-forest stratum was sampled and so we are able to include it.  The open-forest stratum was previously heavily grazed, and, since the removal of cattle in 1988, regeneration has proceeded naturally \citep{maxfield_hakalau_1998}. The closed-forest stratum was historically least modified by grazing and is relatively intact forest habitat.  The northern boundary of the study area follows the refuge boundary while to the east it is bounded by a fence line (Fig. \ref{fig:2002studyareapointspt}). The southern boundary is the same as that in \cite{camp_population_2010}, chosen to exclude unsurveyed regions to the south of Hakalau but does not represent a physical boundary. To the west of the study area is pasture that is dominated by grass and is unsuitable habitat for \akepa{} and the boundary here marks the edge of the forest.

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.5]{figures/study_area_design.png}
	\caption{Study area showing the 2002 survey points (black dots) in Hakalau Forest National Wildlife Refuge, \hawaii{} Island.  Eastings and Northings are in kilometres.}
	\label{fig:2002studyareapointspt}
\end{figure}

The survey follows a point-transect distance sampling design, recording the horizontal distances from observers to detected birds. Surveys commenced at dawn and continued until 11:00 or halted when weather conditions exceeded prescribed conditions that hindered detecting birds (light rain, and wind and gust strength greater than Beaufort scale 3). During 8-minute counts, trained observers recorded the species, distance to the nearest metre and detection type for each bird detected, along with the sampling conditions cloud cover, rain, wind strength, gust strength, and time of day each point was surveyed.  \cite{camp_population_2010,camp_statespace_2016} provide a detailed description of Hakalau, the study area and the bird surveys.

The survey data in the open forest stratum is available for download \citep{camp_datarelease_2002} and the full time series data was analysed in a spatio-temporal context in \citep{camp_dsm_2020}.  For the purposes of our analysis we select a single survey year from the \akepa{} time series (2002) that contains a broad sampling of the study area with sufficient numbers of detections to estimate detectability. In 2002, there were a total of 289 point transects sampled within the 4,603 ha study area of Hakalau. (Fig. \ref{fig:2002studyareapointspt}) A total of 276 \akepa{} were detected on 121 point transects. The number of detections within each point transect ranged from zero to six. We selected data from a single year to demonstrate our approach in a simplified setting that does not require a temporal model component.  The choice of year is somewhat arbitrary and the model has also been tested analysing data from other years with similar results to those presented here.  However, our approach is readily extendible to a multi-year analysis, similar to that in \cite{camp_dsm_2020}, which we discuss in more detail in Section \ref{sec-discussion}.

\vfill

\section{Distance sampling as a thinned point process}
\label{sec-ds-pp}

\subsection{Overview of distance sampling methods}

Distance sampling methods aim to estimate abundance by using a spatially explicit sampling design and a parametric detection function to estimate the detectability of animals as a function of distance from transect or observer \citep{buckland_advanced_2004, buckland_distance_2015}.  Standard distance sampling approaches use a hybrid of design- and model-based inference to estimate population size.  The probability of detection is modelled using a parametric equation and, given estimates of detectability, a randomized sampling design allows for the construction of Horvitz-Thompson-like estimators of animal density \citep{ buckland_advanced_2004, horvitz_generalization_1952}.  Under this approach, animal density is uniform within each strata of the survey.  

More recently, interest has focused on fully model-based approaches that model a spatially varying animal density and allow for the use of non-random survey designs.  These methods allow animal density to be associated with spatially-indexed covariates and non-parametric random effects.  Therefore, animal density can, in principle, be estimated or predicted for any subregion within the study area \citep{johnson_model-based_2010, miller_spatial_2013, buckland_model-based_2016}.  As such, varying density estimates are not restricted by the stratification design required for Horvitz-Thompson-like estimators.  This additional flexibility to make predictions for smaller, user-specified geographic units, and extrapolate relationships to unsurveyed regions has made model-based distance sampling a common approach in the literature \citep{garciabaron_modelling_2019, herr_aerial_2019, breen_new_2017, williams_chilean_2011, stokes_monitoring_2010, williams_modeling_2006}.

Model-based distance sampling has most commonly been implemented in a two-stage modelling framework.  In the first stage, detectability is estimated using the frequency of observed distances to fit the detection function.  In the second stage, detectability estimates from the first stage are used as an offset in a generalized additive model framework.  Detections are are binned into counts within user-defined sampling units (usually point transects or segments of line transects) and an appropriate response distribution is chosen to model these counts.  The \texttt{dsm} package \citep{miller_spatial_2013}, for example, provides tools to do this using the \texttt{R} package \texttt{mgcv} \citep{wood_gam_2017} to implement the spatial count model.   Due to the often sparse nature of wildlife survey data, this may require consideration of over- or under-dispersion and zero-inflated distributions and the negative-binomial or Tweedie distributions are common choices.  This two-stage approach has come under the name \textit{density surface models} and \cite{miller_spatial_2013} provide a review.

A key concern with the two-stage approach is the propagation of uncertainty from the detection model to the spatial model.  Early attempts to address this focused on bootstrapping \citep{lahiri_resampling_2003, hedley_spatial_2004} but more recent work has pointed to potential difficulties with the bootstrapping approach, noting the difficulty of choosing the resampling units when combining spatially structured random effects and spatial bootstraps \citep{bravington_VariancePropagationDensity_2021, williams_chilean_2011}. Instead, \cite{bravington_VariancePropagationDensity_2021} propose avoiding bootstrapping by propagating error based on a second-order Taylor approximation of the detection function at the first-stage maximum-likelihood estimate.

Concerns about uncertainty propagation can be avoided by using one-stage modelling approaches.  One-stage analyses of distance sampling data have tended to be Bayesian and use Markov chain Monte Carlo (MCMC) methods for inference, usually requiring data augmentation to model unobserved individuals or groups
% problem with this Royle reference here.  Not sure what I was intending to cite.
\citep{royle_HierarchicalModelSpatial_2008, schmidt_using_2012}.  \citet{oedekoven_bayesian_2014} present a one-stage model that avoids data augmentation and incorporate model uncertainty using reversible jump MCMC.

The only Bayesian one-stage analysis that does not use MCMC is, to the best of our knowledge, \citet{yuan_point_2017}, who use INLA \citep{rue_approximate_2009} and present an application on line transect distance sampling data.  \citet{yuan_point_2017} take a point process perspective and formulate the detection model as a thinning of a point pattern.  Key to their approach is formulating the detection model as the solution to an SPDE.  An approximate solution the SPDE is constructed using a B-spline basis and finite element methods which results in a sparse prior precision matrix for the detection model parameters which can be incorporated into the model in INLA.  

A major downside to this approach is that the solutions to the detection model SPDE are not necessarily monotonically decreasing, usually a key feature of detection functions.  The authors' suggestion to reject any non-monotonically decreasing functions when sampling from the posterior is potentially computationally wasteful. Representing the observation model as an SPDE also differs substantially from standard distance sampling models that use a parametric model for the detection function.  This may have hindered a wider adoption of using INLA for distance sampling analyses, \cite{yuan_point_2017} remains the only example we are aware of.  Furthermore, parametric forms of detection functions are readily extendible by including covariates and random effects to explain variation in detectability.  It is not clear how to do this the SPDE formulation.  These differences with traditional distance sampling methods have perhaps lead to low uptake amongst practitioners of this approach, despite the computational advantages of INLA and the benefits of a one-stage modelling process.  

Here we present an approach that is closely related to \citet{yuan_point_2017}.  We also fit the model using INLA and take advantage of the benefits the increased computational efficiency compared to MCMC.  However, we avoid the issues with the SPDE detection model, instead allowing the user to specify a parametric family of detection functions, such as the half-normal detection function, as will be more familiar to users of classical distance sampling methods. However, this parametric form results in components of the additive predictor that are non-linear in their parameters, making model fitting infeasible in the \texttt{R-INLA} implementation of INLA \citep{rue_approximate_2009}.  We address this by using a method of iterated model fits based on a first-order Taylor expansion of the non-linear model components and implemented in the \texttt{inlabru} package \citep{bachl_inlabru_2019}.

We fit the model to point transect \akepa{} data, which differ from line transect methods in that there is a need to account for the increasing area surveyed as distance increases from the transect.  Our analysis is, to the best of our knowledge, the first analysis of point transect distance sampling data formulated as a thinned point process.  However, the point process viewpoint is not new and has been taken numerous times in analyses of line transect data \citep{buckland_model-based_2016, niemi_bayesian_2010, johnson_model-based_2010, waagepetersen_likelihood-based_2006, hedley_spatial_2004,  hogmander_random_1991, stoyan_remark_1982}.

\vfill

\subsection{Model specification}

This section describes the statistical model for the spatial pattern of observed animal locations. We assume the location of animals are a point pattern that follows a log-Gaussian Cox process with intensity process $\lambda$, i.e.  the intensity at location $\bs$ is a random variable denoted $\lambda(\bs)$.  The log-Gaussian Cox process is a flexible model that can include spatial covariates to model the mean intensity as well a mean-zero spatially structured random effect to account for unexplained heterogeneity not captured by the covariates \citep{moller_log_1998}.  To account for the imperfect detection of points we specify a thinning probability function $g(\bs) = \mathbb{P}(\text{a point at $\bs$ is detected } |\text{ a point is at $\bs$})$. A key property of the log-Gaussian Cox process is that the point pattern of \textit{detected} points itself follows a log-Gaussian Cox process with intensity process $\tl(\bs) := \lambda(\bs)g(\bs)$.  Using a log link $\log g(\bs)$ is therefore included in the model as an additive component to the model for $\log \lambda(\bs)$.  

Distance sampling models specify the thinning function $g(\bs)$ as a function that decays with increasing distance.  The type of distance measured depends on the type of survey.  For line transects the perpendicular distance to the transect line is used whereas for point transects it is the horizontal distance to the observer.  For the remainder of the paper we assume a point transect survey design and hence horizontal distance to an observer located at the centre of each point transect.  

The thinning probability function is specified as a parametric family of functions. For example, if $r(\bs)$ denotes the distance of a point at $\bs$ from an observer, the half-normal thinning probability function is $g(\bs | \sigma) = \exp(-r(\bs)^2 / 2\sigma^2)$, where $\sigma^2 > 0$ is a variance parameter to be estimated.  Other types of detection function, such as hazard-rate, negative exponential, can also be used. Their parameters themselves can be modelled using appropriate link functions to incorporate covariates that may affect detectability.  In addition to these parametric forms, additional adjustments have been proposed to increase the flexibility of such models by including trigonometric series expansions \citep{buckland_distance_2015}.  

In this analysis we assume a half-normal detection function with no covariates on detection parameters to demonstrate the approach in a simplified setting.  The detection function parameters can only be estimated if an assumption is made about $\lambda(\bs)$ otherwise $g(\bs)$ and the intensity are confounded.  The standard assumption in distance sampling is that the intensity is constant with respect to changes in $r(\bs)$. The usual approach for two stage models is to assume $\lambda(\bs)$ is constant within each spatial unit, however we are able to relax this assumption slightly to allow $\lambda(\bs)$ to be a linear function within in each transect.  Given such an assumption, any observed deviations from uniformity can be attributed to detectability and not to variation in the intensity.

A point transect distance sampling survey consists of a set of $K$ point transects.   We denote $k$th subset of space covered by the $k$th point transect as $\Omega_k \subset \mathbb{R}^2$ and the total surveyed region is $\Omega = \cup_{k=1}^K \Omega_k$.  For simplicity, we assume that all point transects are non-overlapping disks with equal radius $W$, as is the case in the HFBS survey.  It would be straightforward to relax this assumption.  The probability of observing a point at location $\bs \in \Omega_k$ given it is at $\bs \in \Omega_k$ we denote $g_k(\bs)$.  The probability of observing a point outside the surveyed region is zero.
Since the point transects are non-overlapping, each location $\bs \in \Omega$ is unambiguously associated with a single thinning probability function $g_k$.  For example, letting $\bs_k$ denote the centre of transect $\Omega_k$, the half-normal thinning probability function for points in $\Omega_k$ is $g_k(\bs) = \exp(-\lVert \bs - \bs_k \rVert_2^2 / 2\sigma^2)$.  The assumption of non-overlapping survey regions could be relaxed by including extra information such as the time of each observation.  The thinning probability function for any $\bs \in \Omega$ is then given by $g(\bs) = g_{k(\bs)}(\bs)$ where $k(\bs)$ is an indexing function such that $k(\bs) = k$ for $\bs \in \Omega_k$.

The thinned log-Gaussian Cox process likelihood for observed points at locations $\bm{Y} = (s_1, \ldots, s_n)^\intercal$ is
\begin{equation}
\label{lgcp-likelihood}
\pi(\bm{Y}) = \exp\left( |\Omega| -\int\displaylimits_{\bs \in \Omega} \lambda(\bs) g(\bs) \mathrm{d}\bs \right)\prod_{i=1}^n \lambda(\bs_i)g(\bs_i),
\end{equation}
where $|\Omega|$ is the area of the total surveyed region and $\lambda(\bs)$ and $g(\bs)$ both depend on parameter vectors omitted for readability.  

\subsection{Writing the model as a modified Poisson likelihood}

\sloppy The likelihood \eqref{lgcp-likelihood} contains an integral that cannot be solved analytically.  A common approach for fitting log-Gaussian Cox processes in practice is to approximate the likelihood by replacing the integral with a weighted sum.  In this section we describe this approximate likelihood and show how it can be written as a modified Poisson likelihood.  We follow closely with the approach given in \cite{simpson_going_2016} for a fully observed log-Gaussian Cox process but adapted for the point transect distance sampling case.

To evaluate the integral we use polar coordinates notation $\bs_k(r, \theta) = \bs_k + r\left[\cos\theta, \sin\theta \right]^T$ with $r \in [0, W]$ and $\theta \in [0, 2\pi]$ to represent locations in each sampling unit $\Omega_k$.  In a slight abuse of notation $\bs_k$ denotes the centre of the point transect and $\bs_k(r,\theta)$ describes any location within the transect.  It should be clear from context which is intended by $\bs_k$.   The thinning function $g_k(\bs_k(r, \theta))$ depends only on $r$ and not on $\theta$ and so we use the shorthand notation $ g(\bs_k(r, \theta)) = g_k(r)$. 

The integral in the likelihood can be simplified using an assumption that $\lambda(\bs)$ is linear within each sampling unit.  This implies that $\lambda(\bs_k(r, \theta)) + \lambda(\bs_k(r, \theta + \pi)) = 2\lambda(\bs_k)$.  Therefore
\begin{align}
\label{eq-linear-intensity}
	\int_0^{2\pi} \lambda(\bs_k(r, \theta))g_k(r)\mathrm{d}\theta &= \int_0^\pi \{\lambda(\bs_k(r, \theta)) + \lambda(\bs_k(r, \theta + \pi) \} g_k(r)\mathrm{d}\theta \nonumber \\
	&= 2\pi \lambda(\bs_k)g_k(r).
\end{align}
We note that this is a relaxation of the traditional assumption in distance sampling that the intensity is constant within each sampling unit.  A similar relaxation is also possible in the case of line transects \citep{yuan_point_2017} and this assumption complements the choice of piecewise linear basis functions used for the GMRF spatial effect (Section \ref{sec-gmrf}).  

It follows that $\int \lambda(\bs)g(\bs) \mathrm{d}\bs = \sum_{k=1}^K 2\pi \lambda(\bs_k) \int_0^W r g_k(r)\mathrm{d}r$ by applying the change of variables formula for integration and substituting in \eqref{eq-linear-intensity}.  Note that this integral now only involves the one dimensional integral with respect to $r$.  For each sampling unit we approximate this integral using a midpoint integration method with $M$ integration locations $r_{k1}, \ldots, r_{kM}$ and associated weights $\alpha_{k1}, \ldots, \alpha_{kM}$.  This gives
\begin{equation*}
	\int\displaylimits_{\bs \in \Omega} \lambda(\bs)g(\bs)\mathrm{d}\bs \approx \sum_{k=1}^K \sum_{j=1}^M \tilde{\alpha}_{kj} \tl(\bs_{kj}) ,
\end{equation*}
where $\tilde{\alpha}_{kj} = 2\pi \alpha_{kj}r_{kj}$ and $\tl(\bs_{kj}) = \lambda(\bs_k) g_k(r_{kj})$.

To simplify notation below we gather all integration weights into the vectors $\tilde{\alpha}_{k} = (\alpha_{k1}, \ldots, \alpha_{kM})^\intercal$ and $\tilde{\alpha} = (\alpha_1^\intercal, \ldots, \alpha_K^\intercal)^\intercal$.  Similarly, let $\tl_k = (\tl(\bs_{k1}), \ldots, \tl(\bs_{kM}))^\intercal$, $\tl_{int} = (\tl_1^\intercal, \ldots, \tl_K^\intercal)^\intercal$, the thinned intensity evaluated at each integration location, and $\tl_{obs} = (\tl(\bs_1), \ldots, \tl(\bs_n))^\intercal$, the thinned intensity evaluated at each observation location.  Then the approximate log-likelihood can be written as
\begin{equation}
\label{approx-log-likelihood}
	\log \pi(\bm{Y}) \approx - \tilde{\alpha}^\intercal \tl_{int} + 1^\intercal\log\tl_{obs}.
\end{equation}
This approximate likelihood can be expressed as a modified Poisson likelihood by letting $\eta = (\tl_{int}^\intercal, \tl_{obs}^\intercal)^\intercal$,
$\alpha = (\tilde{\alpha}^\intercal, 0_{n \times 1}^\intercal)^\intercal$ and constructing a vector of pseudo-observations $z = (0_{KM\times 1}^\intercal, 1_{n \times 1}^\intercal)^\intercal$.  Then the approximate likelihood is
\begin{equation}
\pi(\bm{Y}) \approx C \prod\limits_{i=1}^{KM + n} \eta_i^{z_i}\exp(-\alpha_i\eta_i),
\end{equation}
where $C$ is a constant.  This approximate likelihood is implemented in \texttt{inlabru} as a \texttt{"cp"} likelihood.  

The approach taken here is similar to the Berman-Turner device \citep{berman_approximating_1992, baddeley_practical_2000} although without the assumption that the locations of observed points form a part of the quadrature scheme.

\subsection{Intensity functions for incomplete data}

In the above, we assume the data are complete records of animal locations.  That is, each observation has a known position $\bs_{k(\bs_i)} = \bs_{k(\bs_i)}(r_i, \theta_i)$.  However, in many distance sampling surveys only the location of the observer and the distance to the observer are recorded.  Data of this type can be analysed within a point process framework by deriving the appropriate intensity function.  We consider the case where $r$ is recorded but not $\theta$.  It follows that the intensity for points at a distance $r$ observed within sampling unit $\Omega_k$ is
\begin{align}
\label{intensity-incomplete}
\tl_k(r) &= \oint\displaylimits_{c_k(r)} \lambda(\bs)g_k(r)\mathrm{d}\bs \nonumber \\
&= 2\pi\lambda(\bs_k)rg_k(r),
\end{align}
where $c_k(r)$ is a circle of radius $r$ centred at $\bs_k$ and the second line follows from change of variables and the assumption of linear intensity within $\Omega_k$.  This intensity differs from the full data case through the $2\pi$  term that accounts for the fact that we do not observe $\theta$ and the additional $r$ term that accounts for the increasing area surveyed at larger distances.  We note that a similar equation is derived from the perspective of a triangular distribution for point transect distance sampling in \cite{buckland_advanced_2004}.  

The log-intensity for detected points is therefore $\log\tl(\bs) = \log 2 \pi r + \log\lambda(\bs) + \log g(\bs)$ and so it is straightforward to account for incomplete location information by including an offset term.  As we noted above, the detection function $g(\bs)$ is non-linear in its parameters and this component of the additive predictor requires a novel approach to parameter estimation.

\section{Iterated INLA}
\label{sec-iinla}

The half-normal detection function depends on the strictly positive parameter $\sigma^2$. Since it is not possible to restrict the range of parameters to be strictly positive within \texttt{R-INLA} this model cannot be fitted using the standard INLA methodology.  Instead, we choose a log link and consider $g(\bs | \phi)$, where $\log\sigma^2 = \phi$. This is a non-linear function of $\phi$ which cannot be fitted using standard GLM methods.  To address this we use a novel approximate method based on a first-order Taylor approximation of the non-linear predictor.  

Let $\eta(\bm{u}) = \log \tilde{\lambda}(\bm{u})$ where $\bm{u}$ is the parameter vector of the predictor (which includes $\phi$ as well as any parameters for fixed and random effects).  Denote by $\bar{\eta}_{\bm{u}_0}$ the first-order Taylor approximation of $\eta(\bm{u})$ at the point $\bm{u}_0$.  That is
\begin{equation*}
\bar{\eta}_{\bm{u}_0} (\bm{u}) = \eta(\bm{u_0}) + \bm{B}_{\bm{u}_0}(\bm{u} - \bm{u}_0),
\end{equation*}
where $\bm{B}_{\bm{u}_0}$ is the derivative matrix of $\eta(\bm{u})$ evaluated at $\bm{u}_0$.  Since $\bar{\eta}_{\bm{u}_0}$ is linear in $\bm{u}$ it is possible to fit an approximate model in INLA by replacing the non-linear $\eta$ with the linear Taylor approximation $\bar{\eta}_{\bm{u_0}}$.   

The question then is how to choose the linearisation point $\bm{u}_0$.  To find an `optimal' linearisation point we use a fixed point iteration scheme.  There are various possible choices to define an `optimal' choice and this affects the properties of the approximate inference method.  Here we describe the criteria used when fitting the model that produces the results presented in this paper.  However, more recently, other options have been added to \texttt{inlabru}, the software package that implements these methods.

We denote by $\bar{p}_{\bm{v}}$ the posterior distribution of the model parameters given the linearised model configuration at linearisation point $\bm{v}$.  New linearisation points are found by considering the functional
\begin{equation}
	f(\bar{p}_{\bm{v}}) = \left\{ \argmax_{\bm{u}_i} \: \bar{p}_{\bm{v}}(u_i | \bm{Y}), \quad i = 1, \ldots, n_{\bm{u}} \right\}
\end{equation}
where $n_{\bm{u}}$ is the length of $\bm{u}$.  Each marginal posterior $\bar{p}_{\bm{v}} (u_i | \bm{Y})$ and their modes are estimated during the model fitting using the standard INLA method and so this functional can be evaluated at no extra cost for each fit of the linearised model.
We then seek a fixed point of this functional so that $\bm{u}_0 = f(\bar{p}_{\bm{u}_0})$.  This fixed point is identified via an iterative scheme.  Given a current choice of linearisation point $\bm{v}$, estimate $\bar{p}_{\bm{v}}$ and set $\bm{u}_* :=f(\bar{p}_v)$ to use as the new linearisation point.  We iterate this procedure until a fixed point is identified within a chosen tolerance.

In practice the point $\bm{u}_*$ may be problematic and result in a linearised model configuration that is challenging to fit.  Instead this point is considered only as an initial candidate point.  The next linearisation point is chosen by setting $\bm{u}_{\alpha} = (1 - \alpha)\bm{v} + \alpha \bm{u}_*$ and finding the value of $\alpha$ that minimises $ \lVert \eta(\bm{u}_{\alpha}) - \bar{\eta}_{\bm{v}} \rVert$.  This means that the new linearisation point remains close to a feasible region for fitting, assuming the current point $\bm{v}$ is reasonable.  In practice, we have found that this requires some care when choosing starting values for the initial model fit.  We estimate $\alpha$ using an approximate line search method that avoids many potentially expensive evaluations of the non-linear predictor.  This iterative method is implemented in the R package \texttt{inlabru} \citep{bachl_inlabru_2019} which is both a wrapper and an extension to \texttt{R-INLA}.

\section{Spatially Structured Random Effect}
\label{sec-gmrf}

This section describes the spatial model for the intensity process.  
As mentioned above, the \akepa{} population exhibits spatially heterogeneity for which there is no known explanatory covariate.  Therefore we use a spatially structured random effect to explain this variation.

Using spatially-structured random effects can be computationally expensive.  Often this is due to parameterisations and approximations that lead to dense prior precision matrices which have an  $\mathcal{O}(k^3)$ cost to factorise for an effect with $k$ basis parameters.  A key development in the development of computationally efficient methods is the use of sparse Gaussian Markov random field (GMRF) representations of Gaussian random fields (GRFs).  These result in a sparse precision matrix which can be factorised with a cost of $\mathcal{O}(k^{3/2})$.  We use a GMRF representation based on a stochastic partial differential equation approach \citep{lindgren_explicit_2011}.  This representation is constructed by applying finite element methods to solve the SPDE numerically.

Since only the distance to the observer was recorded, and not the exact location of \akepa{}, we used the adjusted intensity given in equation \eqref{intensity-incomplete}.  The log-intensity of animal locations, detected or undetected, is given by
\begin{equation*}
\log \lambda(\bs) = \beta_0 + \xi(\bs)
\end{equation*}
where $\beta_0$ is an intercept parameter and $\xi(\bs)$ is a mean zero GRF with Mat\'ern covariance.  The Mat\'ern covariance function in two dimensions can be written as 
\begin{equation}
C(\bs_1,\bs_2) = \frac{2^{1-\nu}}{4\pi\kappa^2\tau^2\Gamma(\nu)}(\kappa \|\bs_1-\bs_2\|)^{\nu}K_\nu(\kappa \|\bs_1-\bs_2\|)
\end{equation}
where \(\nu, \kappa, \tau\) are parameters and \(K_{\nu}\) is the modified Bessel function of the second kind.  The three parameters are not simultaneously identifiable \citep{zhang_inconsistent_2004} and it is conventional to assume a value for $\nu$ which specifies the mean-square differentiability of the process.  We set $\nu = 1$ which is the default value in \texttt{R-INLA}.

We use a GMRF representation of $\xi(s)$ following the approach of \cite{lindgren_explicit_2011} based on specifying $\xi(s)$ via a SPDE.  We define a finite element mesh with $L$ nodes and associated piece-wise linear basis functions $\phi_1, \ldots, \phi_L$. The GRF is represented as $\xi(\bs) = \sum_l \beta_l \phi_l(\bs)$.  The parameters $\beta_1, \ldots, \beta_L$ form a GMRF with sparse prior precision matrix $\bm{Q} = \frac{1}{\tau^2}\left(\kappa^4\bm{C} + 2\kappa^2\bm{G_1} + \bm{G_2}\right)$ where $\bm{C}$, $\bm{G_1}$, $\bm{G_2}$ are all sparse matrices (see Appendix [BLAH]). The parameters $\tau$ and $\kappa$ control the shape and rate of decay of the Mat\'ern covariance function as distance between locations increases. We used a finite element mesh with 3748 nodes defined over the entire study region and extended over a buffer region to avoid the effects of boundary conditions within the region of inference.

In order to specify priors on the Mat\'ern covariance below we use a reparameterisation of $\kappa$ and $\tau$ to a range and variance parameter.  When $\nu = 1$ and the domain is two dimensional then the reparameterisation is $\rho = \sqrt{8} / \kappa$ for the range and $\sigma^2 = 1 / (4\pi\kappa^2\tau^2)$ for the marginal variance (\cite{blangiardo_spatial_2013}, p196).  This parameterisation is used to set penalised complexity priors \citep{simpson_penalising_2017} on $\rho$ and $\sigma^2$ which allow the GRMF effect to shrink towards zero.  For the Mat\'ern field, the base model is the limiting case with $\sigma^2 \rightarrow 0$ and $\rho \rightarrow \infty$, which defines a random field that is almost surely zero everywhere.  The purpose of penalised complexity priors is to place sufficient prior probability on a simple model to allow the random effect to be essentially `turned off' if the model component is not supported by the data.  

To specify penalised complexity priors on the SPDE effect we set $\mathbb{P}(\sigma > 2) = 0.01$ and $\mathbb{P}(\rho < 130) = 0.01$.  The value of 130 for the range parameter was selected based on the minimum distance between sampling locations.  

The SPDE approach can at first appear to be fundamentally different  other approaches such as penalised regression splines.  However, the two methods are closely related and the GRF model component in our model plays a similar role to a penalised smoothing spline on space.  \cite{yue_bayesian_2014} show how spline models can be viewed through the perspective of SPDEs and \cite{ miller_understanding_2019} do the reverse to show how to implement the Mat\'ern SPDE as a penalised spline model in \texttt{mgcv} \citep{wood_gam_2017}.

\section{Results}
\label{sec-results} 

The model fits 40 to 60 seconds on a laptop with 10 Gb RAM and a 2.50 GHz CPU when INLA is run using the `empirical Bayes' option which does not incorporate uncertainty in hyper parameters.  The model fits in minutes in full INLA mode including hyper parameter uncertainty.  We suggest using the `empirical Bayes' mode for model development and full INLA on a smaller subset of candidate models.  

The predicted mean of the posterior intensity field is shown in \autoref{fig:intensity-mean-cv}A along with a map of the coefficient of variation (CV) (\autoref{fig:intensity-mean-cv}B) and standard deviation of the posterior intensity field (\autoref{fig:intensity-mean-cv}C) on a regular prediction grid with each prediction cell area approximately 1.7 hectares.
\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.525]{figures/intensity_mean_cv_sd.png}
		\caption{The A) mean, B) CV and C) SD of the posterior intensity field.  Units are per m$^2$}
		\label{fig:intensity-mean-cv}
	\end{center}
\end{figure}
This shows a region of high intensity in the south and much lower intensity in the north, agreeing with a standard two-stage analysis of the same data \citep{camp_dsm_2020}.  The CV plot shows that the CV in the posterior intensity field is lower in areas with greater sampling effort and higher intensity.  There is a clear indication of preferential sampling with more survey effort in the south, where densities are higher, compared to the north.  In the north, estimated intensities are lower, which also contributes to larger CV values and makes the CV map hard to interpret.  The standard deviation map shows stronger overall posterior variability in the south where intensity is larger, most likely due to the assumed log-normal relationship between the random field and the Poisson rate parameter.  

We also map the lower and upper quantiles corresponding to a 95\% credible interval for each prediction location (Figure \ref{fig:intensity-quantiles}).  As we discuss below, these quantiles are independent summary statistics of the posterior intensity field at each prediction location.  
\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.525]{figures/intensity_quantiles.png}
		\caption{The predicted posterior intensity quantiles:  A) 0.025 quantile B) 0.975 quantile.  Both plots plots use the same colour scale}
		\label{fig:intensity-quantiles}
	\end{center}
\end{figure}

The posterior detection function (\autoref{fig:det-matern}) shows that detectability drops to just under 0.25 at the maximum observable distance of 58 metres and also broadly agrees with a two-stage analysis.
\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.525]{figures/detfn_and_matern.png}
		\caption{A) Posterior half-normal detection function. B) Posterior Mat\'ern correlation function.  The black line is the mean posterior estimate and the grey shaded area is 95\% credible interval in both plots}
		\label{fig:det-matern}
	\end{center}
\end{figure}
The posterior Mat\'ern correlation function is shown in \autoref{fig:det-matern}; the grey regions show the 95\% credible interval.  We note that this correlation function shows positive correlation even at distances of 10,000 metres, wider than the full length of the study region (approximately 8,000 metres).  This is because this is the correlation range on the log-intensity scale.  On the intensity scale the empirical range of correlation is shorter.

To evaluate the ability of the SPDE effect to capture the spatial heterogeneity in the observed data we generated 1,000 point patterns using the posterior intensity field and thinned them with the posterior detection function to create 1,000 simulated datasets to compare with the observed data.  We calculated the pairwise distances between all observations for each of these datasets and compared the frequency of pairwise distances with those in the observed data.
\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.6]{figures/post_pp_distances.png}
		\caption{Boxplots of the frequency of pairwise distances (tick mark values for end of each bin) based on 1,000 simulated datasets.  Red circles indicate the frequency of pairwise distances in the observed data.}
		\label{fig:post-pp-distances}
	\end{center}
\end{figure}
Figure \ref{fig:post-pp-distances} shows that the SPDE effect broadly captures the spatial clustering in the observed data.  There is some evidence of under-predicting the strength of the clustering at shorter distances between 1,000 and 2,500 m, with the simulated data showing some evidence of negative bias.  This could be due to over-smoothing in some areas which can happen if using a stationary model.  Large areas of the study region having low density, which has a larger correlation range than higher density areas, and so the effect will average between these. 

Figure \ref{fig:post-pp-distances} is similar in spirit to Ripley's $K$-function \citep{ripley_SecondorderAnalysisStationary_1976}, which is a common approach to investigating spatial structure in point patterns.  The pairwise distances in the observed data is a function of spatial heterogeneity as well as the spatially restricted sampling scheme.  Other methods of comparison could also be considered such as the average difference between predicted and observed counts at each point transect.  Working with posterior predictive datasets is a flexible approach to model evaluation that allows for innovative methods of comparison with observed data that can focus on particular features of the model.

To plot the posterior abundance estimate for the \akepa{} in Hakalau reserve we use a Monte Carlo method based on sampling realisations of the posterior intensity field.  Let $n$ denote the abundance of the population within the region of interest and $N = \int_{\Omega}\lambda(\bs)\mathrm{d}\bs$ its corresponding random variable within our Bayesian framework.  Integrating the mean of the posterior intensity field provides a point estimate for the abundance, i.e. the expected abundance.  To generate a full posterior estimate for abundance we approximate the posterior $\pi(N | \bm{Y})$ by taking $m$ Monte Carlo samples of the posterior intensity field, $\lambda^{(1)}, \ldots, \lambda^{(m)}$ and approximate the posterior for the abundance as $\pi(N | \bm{Y}) \approx 1 / m \sum_{i=1}^m \pi (N | \lambda = \lambda^{(i)}, \bm{Y})$. Each $\pi(N | \lambda = \lambda^{(i)}, \bm{Y})$ is a Poisson probability mass function with rate parameter $\int_{\Omega}\lambda^{(i)}(\bs)\mathrm{d}\bs$. 
\begin{figure}[!htb]
	\begin{center}
		\includegraphics[scale=0.525]{figures/N_posterior.png}
		\caption{Posterior abundance.  Grey area marks two Monte-carlo standard errors above and below the mean}
		\label{fig:realized-abundance-posterior}
	\end{center}
\end{figure}

\autoref{fig:realized-abundance-posterior} shows the approximate posterior for $N$ with $m = 20,000$.  This allows us to estimate the probability for any specific value of realised abundance $n$ which may be of interest to conservation managers.  This approach can also be used to generate credible intervals and other posterior summaries of interest. 

The abundance estimates broadly agree with a standard two-stage analysis of the data \citep{camp_dsm_2020} but the attractive feature of the one-stage model is that, by using Monte Carlo samples from the joint posterior, model summaries naturally incorporate uncertainty in the detection model.  There is no additional step required to incorporate detection function uncertainty beyond working with samples from the joint posterior.

\vfill

\subsection{Limitations of mapped summaries}

Our presentation of the results above is broadly consistent with approaches taken in the species distribution modelling literature, although maps of predictive uncertainty (\autoref{fig:intensity-mean-cv} and \autoref{fig:intensity-quantiles}) are not always provided.  It is common to see maps of point estimates (e.g. a map of expected density) without any accompanying communication of uncertainty.  It is also common to report a point estimate of the expected abundance along with uncertainty in the point estimate.  However, uncertainty in a point estimate will have lower variance than the variance of the posterior random variable.  For this reason we chose to present the full abundance posterior in \autoref{fig:realized-abundance-posterior} as opposed to uncertainty of a `best guess' for abundance.  Our intention in this section is to highlight further limitations with the model outputs presented above and to suggest ways to address these limitations. 

The most common method to communicate uncertainty in a maps of animal density is to produce maps of some measure of predictive uncertainty, such as the standard deviation or CV \citep{fuller_novel_2018, vallejo_responses_2017,bradbury_mapping_2014} that can be derived from the posterior predictive distribution for the model or bootstrapping in a maximum likelihood context.  Another approach is to map quantiles or the probability of exceeding certain thresholds for each prediction location \citep{russell_avoidance_2016, wilson_hierarchical_2010}.  In Section \ref{sec-results}, we present maps of the CV, standard deviation, and the 0.025 and 0.975 quantiles of the posterior intensity field that are all intended to communicate uncertainty in the spatial distribution of \akepa{} (Figures \ref{fig:intensity-mean-cv}B, \ref{fig:intensity-mean-cv}C, \ref{fig:intensity-quantiles}A, and \ref{fig:intensity-quantiles}B, respectively).  Whilst maps that summarise spatial predictions are useful, they all mask certain properties that may be important when communicating the results of the analysis. 

A map showing the posterior predicted mean across the study region (Figure \ref{fig:intensity-mean-cv}A) is often the key output of a species distribution model.  However, even this relatively innocuous summary statistic can mask important features of the random field since the posterior mean will always be smoother than realisations of the field.
\begin{figure}[!htb]
	\includegraphics[scale=0.525]{figures/intensity_realized.png}
	\caption{Three realizations of the posterior intensity field}
	\label{fig:intensity-realizations}
\end{figure}
\autoref{fig:intensity-realizations} shows three such realisations from the posterior intensity field.  Note that each realisation has a finer-grained spatial structure than is shown in the posterior mean (\autoref{fig:intensity-mean-cv}A).  Hence, considering this finer-grained structure, our interpretation is that the clustering of animals is stronger than might be expected if we only looked at the map of the posterior mean.  This is one example of how a summary statistic can mask important features of the posterior random field.

For model evaluation we recommend plotting multiple realisations of the posterior field as these will more closely resemble the spatial structure of the observed data and thus what we might encounter in the field.  The mean is only a summary of the posterior intensity field and can give a misleading sense of homogeneity, particularly in the high density area in the south, when compared to realisations of the mean.  Presenting multiple realisations, perhaps as an animation, is also an effective way to communicate uncertainty. \cite{bowman_GraphicsUncertainty_2019a} provide an interpolation method that preserves the mean and covariance structure of realisations that smoothly interpolates between realisations.  This avoids abrupt changes that can occur when animating the raw realisations.  

The CV map (\autoref{fig:intensity-mean-cv}B) is also intended to communicate uncertainty.  However, CV values will be higher in regions of low predicted intensity, particularly if the posterior standard deviation is relatively consistent across the study region or positively correlated with the intensity.  The observed higher CV areas in such maps will highlight regions of relatively lower intensity but not necessarily higher overall uncertainty.  This is clearly the case in \autoref{fig:intensity-mean-cv}B.  However, there is also variable sampling effort within the study region and it is not clear what impact this has on the CV map.  This means that the resulting map is hard to interpret.

The standard deviation (SD) map (\autoref{fig:intensity-mean-cv}C) shows spatially varying SD values.  However, care should be taken as to what the mapped values imply in the context of a given analysis.  A default colour scale will nearly always show some spatial variation in uncertainty, with some regions of relatively high and low uncertainty.  What such a map does not show is whether these differences actually matter in the context of the analysis.  For example, it could be the case that the standard deviation values are so large as to make the predictions have an unacceptably high uncertainty everywhere.  Or, on the other hand, perhaps differences between high and low uncertainty regions (where `high' and `low' are defined by the default colour scale for the map) are small enough to be negligible when it comes to making conclusions or decisions, in which case such a spatially varying map may not be a useful output to communicate to decision makers.  These are two extreme examples.  However, even in less extreme situations, the actual practical relevance of the SD values should be considered in order to be able to interpret the map.  

The SD map suffers from another weakness which is that the SD values are linked to the predicted mean since the model assumes a log-Gaussian relationship.  This means that the SD map usually looks similar to the mean intensity map.  This relationship is the result of a modelling assumption and not necessarily reflective of the detectability of animals or survey effort.  One might expect uncertainty to be lower in areas with greater survey effort, however for the \akepa{} data the opposite is the case.  This is another limitation of the SD map.  

The quantile maps (Figure \ref{fig:intensity-quantiles}) are also potentially difficult to interpret. The temptation is to perceive the maps as showing possible intensity surfaces that could have produced the observed data with one possible intensity surface (0.025 quantile map) that signifies lower abundance and another surface (0.975 quantile map) that signifies higher abundance.  However, presenting these quantiles together in a single map obscures the fact that it is vanishingly unlikely for all prediction locations to \textit{simultaneously} achieve their 0.025 or 0.975 quantiles.  A similar problem will occur for maps of the marginal probability of exceeding a threshold at each prediction location.  

Presenting independent quantiles jointly in a single image is risky.  We believe these caveats make the map difficult to use for most non-statistically trained audiences and even trained statisticians may misinterpret these quantile maps if they are not careful.  To demonstrate the possible consequences of this we (incorrectly) treat the lower and upper quantile plots as though they are intensity functions and integrate them to obtain an expected abundance estimate of approximately 2,800 for the 0.025 quantile map and 10,200 for the 0.975 quantile map.  A naive (and tempting) interpretation of these numbers is as lower and upper limits of the 95\% credible interval for abundance. However, these abundance estimates are outside the support of the posterior for abundance (see \autoref{fig:realized-abundance-posterior}).  This demonstrates that the tendency to interpret these maps as showing possible intensity surfaces that are consistent with the observed data can lead to interpretations that are inconsistent with the very model that generated the maps.

We conclude that, although all useful in their own way, each of the mapped summaries of the posterior intensity field suffer from some weaknesses, whether through masking certain properties of the random field or through being difficult or impossible to interpret.  We next present some alternatives that avoid some, but not all, of these problems. 

\subsection{Excursion sets and excursion functions}

Our solution to these problems with quantile and standard deviation maps is to suggest that consideration should be given \emph{a priori} to relevant values of the process and acceptable levels of uncertainty that are suitable given the context and aims of the analysis.  These values can then be used to construct summary maps.  We demonstrate this perspective using excursions sets and excursion functions \citep{bolin_excursion_2015}.  Although there are other possible approaches [[cite here?]], excursions methods are a natural choice for Gaussian random fields.  These methods require the user to specify thresholds of interest for the random field and acceptable levels of uncertainty.  For this reason they avoid the issue of a default colour scale potentially affecting our interpretation of results.  Excursion sets and excursion functions are also based on the joint probability of events across a set of locations.  For this reason they avoid the interpretability issues of the quantile maps.

The positive excursion set with level $u$ for a function $f(s)$ with domain $\Omega$ is $A_u^{+}(f) = \{ s \in \Omega ; f(s) > u \}$, i.e. the set of all locations in $\Omega$ where $f$ exceeds a threshold value $u$. For a stochastic process $\lambda(s)$ the positive excursion set with level $u$ and probability $1 - \alpha$ is
\begin{equation*}
E_{u,\alpha}^{+}(\lambda) = \argmax_{D}\{\lvert D \rvert : \mathbb{P}\left[D \subset A_u^{+}(\lambda)\right] \geq 1 - \alpha \} \;\;\; .
\end{equation*}
Note that $A_u^{+}(f)$ specifies a set for which a function $f(s)$ exceeds a threshold value $u$ for \textit{every location} in the set. As such the positive excursion set $E_{u,\alpha}^{+}(\lambda)$ is the largest such set for which a threshold is exceeded simultaneously for all locations in the set, with a chosen probability.  Negative excursion sets are similarly defined.  Excursion sets can be estimated by considering candidate sets for $D$ of increasing size and a sequential integration scheme to estimate probabilities.  An implementation is available in the \texttt{excursions} package \citep{bolin_calculating_2018} available through the Comprehensive R Archive Network \citep{r_2017}.

\autoref{fig:excursions} (left panel) shows the positive excursion set with a level corresponding to 1 bird per hectare with probability 0.95.  This figure can be interpreted in a natural way as the largest region for which the intensity is greater than 1 bird per hectare for every location within the region, with probability 0.95.
\begin{figure}[!htb]
	\includegraphics[scale=0.5]{figures/excursions.png}
	\caption{Left:  The positive excursion set with a level corresponding to 1 bird per hectare and probability 0.95.  Right: The positive excursion function with a level corresponding to 1 bird per hectare}
	\label{fig:excursions}
\end{figure}
To visualise multiple such maps we can use the excursion function $F_u^{+}(s) = \sup \{1 - \alpha ; s \in E_{u,\alpha}^+ \}$, which defines for each location largest possible probability $1 -\alpha$ for which that location would be in the excursion set defined using probability $1 - \alpha$.  i.e.  if we allow greater uncertainty, which locations would be included in the excursion set.  The excursion function with a level corresponding to 1 bird per hectare is shown in \autoref{fig:excursions} (right panel).  This figure can also be interpreted naturally.  It shows the largest possible probability for each location to be a member of a set in which the intensity exceeds a threshold simultaneously across all locations in the set. It is clear from the figure that regions on the edge of the excursion set would be included if the $\alpha$ value were allowed to increase slightly.  However, for regions in the north there is essentially no probability level for which those locations would be included in $A_u^{+}(\lambda)$.
We chose the threshold of 1 bird per hectare and an error probability of 0.05 to demonstrate the approach.  Multiple values for each of these can be considered as a simple extension.


\section{Discussion}
\label{sec-discussion}

This paper presents a new approach to analysing point transect distance sampling data that incorporates several innovative methods and considers the bulk of an applied statistician's workflow of model specification, inference procedure, model evaluation and communication of results.  Although any of these areas on its own would be substantive enough to be the main focus of a paper, our brief presentation of issues in sequence along with our chosen solutions will be useful to statisticians who face similar questions and data structures.

There are several natural extensions to the model.  For this analysis we only considered a single survey year.  Spatio-temporal extensions to this are possible, for example by considering a space-time interaction models.  \texttt{R-INLA} has the ability to fit space-time effects that can be represented as a Kronecker product of the relevant precision matrices \citep{blangiardo_spatial_2013, yuan_point_2017}.  An example of this type of space-time interaction effect is an interaction between the spatial SPDE with an auto-regressive temporal process.  \cite{blangiardo_spatial_2013} show how this can be done with numerous examples and code snippets.

Another natural extension is to consider more complicated observation processes.  There is the potential to include explanatory covariates on detection function parameters.  For example, we did not make use of the detection type (audio or visual) in our analysis, although this was recorded and detectability may vary depending on whether a bird is seen or heard.  Other factors could be considered, such as weather conditions, observer expertise, animal behaviour and morphological traits.  Any additional parameters to the non-linear model components will be estimated using the outer-optimisation step of iterated INLA.  [[Can I speculate here about how iterated INLA might perform as parameters are added to non-linear components?  Is, higher-dimensional optimisation slower/infeasible/unstable at a certain point?]]

The iterated INLA inference procedure is a general approach that could be applied to other non-linear model components that arise in the area of spatial ecology.  We note two promising areas in which our flexible inference procedure may be useful:

\begin{itemize}
	\item \textbf{Selectivity analysis} In surveys of the marine environment, the size, length and weight of fish affects the likelihood of being caught in a trawl net.  Thus any analysis of these data must account for this.  The probability of capture is typically modelled as a logistic function with parameters that depend on morphological traits \citep{herrmann_understanding_2016, madsen_selectivity_2007, galbraith_demersal_1994}, which could be estimated jointly with the spatial distribution within our inference framework.
	\item \textbf{Functional responses} In the area of understanding species-habitat or species-species interactions, the concept of a `functional response' captures the idea that the abundance of a resource or risk will affect the response to it \citep{holling_some_1959}.  These varying responses can be described mathematically using parametric equations that have the desired properties, e.g. a horizontal asymptote so that beyond a certain threshold no extra amount of a resource will affect the response to it.  These types of responses are typically not considered in species distribution models but our framework allows them to be estimated alongside the more common linear or quadratic fixed effects. This flexibility in specifying model components could also be more widely applicable in areas such as public health and spatial epidemiology, where responses to conditions may be non-linear.

\end{itemize}
We note that many of the themes addressed in this paper apply beyond the field of spatial ecology and will be of interest to the spatial statistics community in general, particularly for applications with complex observation models of latent processes and where spatial predictions are a key output of the analysis

In our analysis we only briefly touch upon the problem of communicating uncertainty in maps and highlight the excursions methods as a new and positive addition to this area.  In our example, the threshold was chosen to illustrate the method but we believe that discussions with relevant stakeholders will lead to agreement on a (possibly large) set of thresholds that are relevant given the aims and context of the analysis.  This requires the input of both the relevant domain experts and statisticians so stakeholders understand the consequences of the thresholds and uncertainty levels they wish to consider.  We also note the potential for excursions to be used to define the notion of occupancy (and thus map occupied areas, with a given probability of error).

We end with a note on the similarity between what we have done and existing two stage approach.  The one-stage thinned point process perspective can seem fundamentally different to a two-stage GAM approach fitted to count data.  It can be tempting to think that, because the point process model does not require us to bin the data into counts, we can avoid some loss of information.  However, we also made the same assumption of constant intensity within each transect as in more traditional distance sampling approaches.  This leads to the same loss of information since we do not use the exact location of points within each transect, except to account for detectability.

In summary, we have presented a novel framework for analysing point transect distance sampling data that introduces new approaches to model specification, inference procedure and communication of results.  These developments will be of interest to those with similar data structures in spatial ecology as well as researchers in other areas who we hope will explore the full flexibility and generality of these developments in their own work.

% spp has potential to provide general framework? [Janine comment]
% Mention modelling on sphere is possible without projecting on to R^2?

\clearpage
\bibliographystyle{stylefile16/rss}
\bibliography{paper}

\end{document}
